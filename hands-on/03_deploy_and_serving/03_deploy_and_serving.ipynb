{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作成したモデルのdeployとserving\n",
    "\n",
    "このハンズオンでは、Vertex AIにモデルをデプロイし、推論APIとして利用できるようにしていきます。\n",
    "\n",
    "先ほど作成した犬種/猫種判別モデルをデプロイすることで、その手順を確認していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## <todo> 自分の名前を入力してください\n",
    "USER=___ # 自分の名前\n",
    "REGION=asia-northeast1\n",
    "BUCKET=mixi-ml-handson-2023\n",
    "MODEL=pet_model\n",
    "\n",
    "gcloud ai models upload \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=oxford-pet-${USER} \\\n",
    "  --container-image-uri=image-uri=asia-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest \\\n",
    "  --artifact-uri=gs://${BUCKET}/${USER}/${MODEL}\n",
    "\n",
    "gcloud ai models list \\\n",
    "  --region=${REGION} \\\n",
    "  --filter=oxford-pet-${USER}\n",
    "    \n",
    "gcloud ai endpoints create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=oxford-pet-${USER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記コードの実行には数分の時間がかかります。  \n",
    "実行が終わったら、出力された`MODEL_ID`と、endpointを作成した際に出力された`ENDPOINT_ID` `'・・・/asia-northeast1/endpoints/<ENDPOINT_ID>'`を使って、endpointにmodelをdeployします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## <todo> ___ 部分を埋めてください\n",
    "USER=___ # 自分の名前\n",
    "REGION=asia-northeast1\n",
    "MODEL_ID=___ # 前のセルで出力されたMODEL_ID\n",
    "ENDPOINT_ID=___ # 前のセルで出力されたENDPOINT_ID\n",
    "\n",
    "gcloud ai endpoints deploy-model ${ENDPOINT_ID} \\\n",
    "  --region=${REGION} \\\n",
    "  --model=${MODEL_ID} \\\n",
    "  --display-name=oxford-pet-${USER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "上記コードの実行には数分の時間がかかります。\n",
    "\n",
    "versionの作成が完了したら、このendpointにリクエストを投げて結果が返ってくるか確認してみます。  \n",
    "まず、02と同じようにデータセットを用意していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "image_size = (200, 200) # Vertex AIのサイズ制限上、意図的に224->200にしています\n",
    "batch_size = 16\n",
    "DATASET_DIR = \"../02_transfer_learning/dataset\"\n",
    "\n",
    "## <todo> ___ を埋めて、02と同じ検証データセットが使えるようにしてください。\n",
    "## このメソッドはdefaultでshuffle=Trueになっているので、同じデータを取得するにはseed値を同じにする必要があります。\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    label_mode='categorical',\n",
    "    seed=___,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットが用意できたら、endpointにリクエストを投げて結果を受け取るメソッドを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "# <todo> ENDPOINT_IDを埋めてください\n",
    "PROJECT_ID = 'hr-mixi'\n",
    "ENDPOINT_ID = '___' # 出力されたENDPOINT_ID\n",
    "REGION = \"asia-northeast1\"\n",
    "\n",
    "def predict_json(instances):    \n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "    endpoint = aiplatform.Endpoint(ENDPOINT_ID)\n",
    "    instances = [json_format.ParseDict(s, Value()) for s in instances]\n",
    "    response = endpoint.predict(instances=instances)\n",
    "    return response.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで結果を受け取る部分はできたので、02で作成したpredict_datasetメソッドのresult部分を、作成したpredict_jsonメソッドに変えてみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset():\n",
    "    for images, labels in val_data.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            image = images[i].numpy()\n",
    "            plt.imshow(image.astype(\"uint8\"))\n",
    "            norm_img = image / 255.0\n",
    "            norm_img = np.expand_dims(norm_img, 0)\n",
    "            norm_img = norm_img.tolist()\n",
    "            ## <todo> ___ を埋めて、予測を受け取れるようにしてください。\n",
    "            result =  ___(___)\n",
    "            plt.title(\n",
    "                \"label:\" + val_data.class_names[np.argmax(labels[i])] +\n",
    "                \"\\npredict:\" + val_data.class_names[np.argmax(result[0])]\n",
    "            )\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = val_data.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "predict_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、modelの部分を推論APIに置き換えることができました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradioを使って犬種/猫種判別を行うデモアプリを作成する\n",
    "\n",
    "model部分のAPI化ができたので、機械学習を使った簡単なデモアプリを作ってみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、お手軽にML系のwebアプリケーションが作成できるgradioをinstallします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --user gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記ImportErrorがでた場合は、kernelをrestartして、<b>bashコマンド以降のセルを改めて実行してみてください。</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完了したら、デモアプリを作成してみましょう。  \n",
    "コード実行ができたら、public URLを確認してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = val_data.class_names\n",
    "\n",
    "def predict(image):\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, 0)    \n",
    "    image = image.tolist()\n",
    "    pred = predict_json(image)[0]\n",
    "    confidences = {labels[i]: pred[i] for i in range(len(labels))}    \n",
    "    return confidences\n",
    "\n",
    "demo = gr.Interface(predict, gr.Image(shape=(200, 200)), outputs=gr.outputs.Label(num_top_classes=5))\n",
    "\n",
    "# <todo> \"\"部分に独自のuserとpasswordを入力してください。\n",
    "# share=Trueになっていると、public URLとして公開されるため、必ず各自でpassを設定して入るようにしてください。\n",
    "demo.launch(share=True, auth=(\"\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "犬種/猫種判定アプリが作れていましたでしょうか。  \n",
    "データセットにない犬、猫などは、  \n",
    "犬は、https://www.min-inuzukan.com/  \n",
    "猫は、https://www.min-nekozukan.com/  \n",
    "にあるので、これらを参考にしつつ正しく判別できるか試してみてください。 "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
