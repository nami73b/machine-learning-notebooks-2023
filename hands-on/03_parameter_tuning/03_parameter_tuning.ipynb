{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータチューニング\n",
    "\n",
    "ハイパーパラメータチューニングは学習を何度も繰り返す必要があり、非常に時間がかかる作業になります。  \n",
    "仮に1回の学習ループが3日かかるとしたら、パラメータを数回変えて試してみるだけで非常に時間がかかってしまいます。\n",
    "\n",
    "今回はその作業をお金の力で解決してしまう方法を学習します。\n",
    "\n",
    "## コードのモジュール化\n",
    "\n",
    "まず、コードを何度も実行するためにはjupyter上で処理するのはあまり向かないため、scriptに落とし込みます。  \n",
    "コードのコアの部分を移動したコードが`mfashion_keras/model.py`にあります。  \n",
    "そして、jobのkickerとなるコードを`mfashion_keras/task.py`に記載してあります。  \n",
    "試しに実行してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このハンズオンで必要なライブラリのインストール\n",
    "!pip install cloudml-hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> このセルを実行する前に、model.pyの<todo>を埋めてください。\n",
    "!python3 -m mfashion_keras.task --output_dir=./output --model=cnn --batch_size=64 --batch_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gcloudコマンドを用いたVertex AIでのtraining実行\n",
    "\n",
    "下記のコマンドをgcloudのVertex AI経由で実行することで、Vertex AI内のリソースを使ってtrainingを実行することができます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 書き換える\n",
    "USER = \"<<username>>\"\n",
    "\n",
    "## 必要に応じて書き換える\n",
    "MODEL_TYPE = \"cnn\"\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_STEPS = 1000\n",
    "\n",
    "## 書き換えなくて良い (出力先を変えたい場合はOUTPUT_DIRを変更)\n",
    "BUCKET = \"mixi-ml-handson-2022\"\n",
    "REGION = \"asia-northeast1\"\n",
    "OUTPUT_DIR = \"gs://\" + BUCKET + \"/\" + USER + \"/mfashion/trained_\" + MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$USER\" \"$BUCKET\" \"$REGION\" \"$MODEL_TYPE\" \"$LEARNING_RATE\" \"$BATCH_SIZE\" \"$TRAIN_STEPS\" \"$OUTPUT_DIR\"\n",
    "\n",
    "DATE=`date +%Y%m%d_%H%M%S`\n",
    "DISPLAY_NAME=mfashion_$5_$1_$DATE\n",
    "\n",
    "echo $8\n",
    "echo ${DISPLAY_NAME}\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=$3 \\\n",
    "  --display-name=${DISPLAY_NAME} \\\n",
    "  --args=\"--output_dir\",$8,\"--train_steps\",$7,\"--model\",$4,\\\n",
    "\"--learning_rate\",$5,\"--batch_size\",$6 \\\n",
    "  --worker-pool-spec=machine-type=n1-standard-4,replica-count=1,accelerator-type=NVIDIA_TESLA_T4,\\\n",
    "executor-image-uri=asia-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest,local-package-path=./mfashion_keras,python-module=task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のコードの実行には数分の時間がかかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行が確認できたら、gcpのコンソールから`vertex AI >> トレーニング >> CUSTOM JOBS`に遷移した後、  \n",
    "リージョンを`asia-northeast1`にして作ったjobが表示されているか確認してみてください。  \n",
    "(実行ログは該当のjobに遷移した後、`ログを表示`ボタンで確認できます。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでjobを作成し、自分のマシン以外のリソースを使って実行できました。  \n",
    "上記のコマンドはjupyter上で実行する必要もないため、もちろんコマンドラインから実行しても同様に実行が可能です。\n",
    "\n",
    "これで自分のマシンの計算リソースの制約にとらわれることなくjobが実行可能になりました。  \n",
    "パラメータを変えながら大量にjobを並列実行すれば最適なパラメータチューニングをすることが可能になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex AIでのハイパーパラメータチューニング\n",
    "　\n",
    "各クラウドで似たような仕組みはありますが、今回はgcloudのパラメータチューニングを使用してチューニングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 必要に応じて書き換える\n",
    "MODEL_TYPE = \"cnn\"\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "## '%%writefile'にglobal変数を読みこませるカスタムマジックコマンド'%%writetemplate'を定義\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最適値を探すのに、`Manual`, `Grid Search`, `Random Search`, `Baysean Search`の4つの探索方法が用意されています。  \n",
    "[詳しくはここ](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs)や[ここ](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/StudySpec)を確認してください。\n",
    "\n",
    "以下はGrid Searchを用いた例です。 \n",
    "今回はlearning_rateを最初値0.001から最大値0.3までの間を探索してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate hyperparam.yaml\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: ccentropy\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: learning_rate\n",
    "    discreteValueSpec:\n",
    "      values: [0.001, 0.005, 0.01, 0.05, 0.1, 0.3]\n",
    "  algorithm: GRID_SEARCH\n",
    "  decayCurveStoppingSpec:\n",
    "    useElapsedDuration: True\n",
    "trialJobSpec:\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-4\n",
    "    replicaCount: 1\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: asia-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\n",
    "      packageUris: [gs://{BUCKET}/{USER}/mfashion/src/mfashion_keras-1.0.tar.gz]\n",
    "      pythonModule: mfashion_keras.task\n",
    "      args: [--output_dir, {OUTPUT_DIR}, --train_steps, \"{TRAIN_STEPS}\", --model, {MODEL_TYPE}, --batch_size, \"{BATCH_SIZE}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> 下のセルを実行する前に、callback.pyの<<todo>>を埋めてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$USER\" \"$BUCKET\"\n",
    "\n",
    "python3 setup.py sdist --formats=gztar \n",
    "gsutil cp dist/mfashion_keras-1.0.tar.gz gs://$2/$1/mfashion/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$USER\" \"$REGION\" \"$MODEL_TYPE\"\n",
    "\n",
    "DATE=`date +%Y%m%d_%H%M%S`\n",
    "DISPLAY_NAME=mfashion_$3_$1_$DATE\n",
    "\n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "  --region=$2 \\\n",
    "  --config=hyperparam.yaml \\\n",
    "  --display-name=${DISPLAY_NAME} \\\n",
    "  --max-trial-count=6 \\\n",
    "  --parallel-trial-count=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行が確認できたら、先ほどと同じようにgcpのコンソールから`vertex AI >> トレーニング >> HYPERPARAMETER TUNING JOBS`に遷移した後、  \n",
    "リージョンを`asia-northeast1`にして作ったjobが表示されているか確認してみてください。\n",
    "\n",
    "また、今回は`ccentropy`という指標を評価に使いましたが、これを変更するにはどうすればいいのでしょうか？確認してみてください。"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
