{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "世の中にはたくさんの学習済みのモデルがあります。それらを使ってTransfer Learningを行います  \n",
    "今回はtensorflow_hubにある学習済みモデルを使います。\n",
    "\n",
    "## 学習済みモデルの再利用\n",
    "\n",
    "まずはモデルを読み込み、使用してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -q -U tf-hub-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4  \n",
    "今回はこのモデルを使用します。mobile_netは軽量で高速なモデルで、精度もそれなりに高く、非常に使いやすいモデルです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに、好きな画像を学習済みモデルでpredictしてみましょう。\n",
    "\n",
    "image_urlに好きな画像のurlを入れてみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "image_url = \"https://dol.ismcdn.jp/mwimgs/7/1/670m/img_71c53c1d81500a1cf73a4f543e72413f27838.jpg\" # 自分で指定\n",
    "\n",
    "img = tf.keras.utils.get_file('inu.jpg', image_url)\n",
    "img = Image.open(img).resize(IMAGE_SHAPE)\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img) / 255.0\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_sizeの分だけ次元を増やしてあげてから、predictしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> これまでと同じようにexpandを使って、batch_size部分の次元を合わせます\n",
    "## ヒント: expandする次元が今までと違うことに注意しましょう(1, 244, 244, 3)\n",
    "img = ___\n",
    "## <todo> classifierを使ってpredictを行います\n",
    "## ヒント: https://keras.io/ja/models/sequential/ でpredictを行うメソッドを確認してください。\n",
    "result = ___ \n",
    "## <todo> 出力のリストから一番確率の高い要素を出力してみましょう\n",
    "## ヒント: https://numpy.org/doc/stable/reference/routines.sort.html から一番高い値のindexを返すメソッドを確認してください。\n",
    "predicted_class = np.___(___, axis=-1) \n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測結果が得られたので、このclass_idがなんに紐づいているのか定義から確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "predicted_class_name = imagenet_labels[predicted_class]\n",
    "print(predicted_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "きちんと学習済みで推論できていることが確認できます。 \n",
    "他にも何枚か試してみてください。\n",
    "\n",
    "ロードしたモデルについても確認しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainable params: 0 からこのモデルが再トレーニングできないモデルなことがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終層を再学習\n",
    "\n",
    "学習済みモデルを利用することで、様々な物体を高精度に判別することができるモデルを、手軽に用意することが出来ました。  \n",
    "しかしこのまま利用するには少し問題があります。再トレーニングができないので、このモデルで学習されていない画像が出た時に判別できないのです。\n",
    "\n",
    "この問題を解決するために、Transfer Learning(転移学習)を行います。  \n",
    "具体的には、最終層やいくつかの層をあえて取り外し、取り外した部分を再学習させるといったことを行います。  \n",
    "これによって、学習済みモデルが持つ高精度な判別能力を維持しつつ、自分の問題設定に合わせた判別が可能となります。\n",
    "\n",
    "では、実際に再学習させてみてTransfer Learningの効果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの確認\n",
    "\n",
    "まず、学習に使うデータセットを用意します。\n",
    "\n",
    "https://www.tensorflow.org/datasets/catalog/overview  \n",
    "上記のカタログの中から、  \n",
    "https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet  \n",
    "こちらのデータセットを今回は使います。\n",
    "\n",
    "では、このデータセットをローカルに持ってきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATASET_URL=https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "curl -o images.tar.gz ${DATASET_URL}\n",
    "tar -xf images.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから使うdataset apiに合わせるため、datasetフォルダの中にペットの種類毎のフォルダを作ってまとめておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"dataset\"\n",
    "for image in os.listdir(\"images\"):\n",
    "    pet_kind = '_'.join(image.split(\"_\")[:-1])\n",
    "    os.makedirs(os.path.join(DATASET_DIR, pet_kind), exist_ok=True)\n",
    "    if image.split(\".\")[-1] == 'jpg':\n",
    "        shutil.copy(\"images/{}\".format(image), os.path.join(DATASET_DIR, pet_kind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset apiの一つである[tf.keras.preprocessing.image_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory?hl=en)を使ってデータセットを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "DATASET_DIR = \"dataset\"\n",
    "\n",
    "## <todo> ↑のURLを参考に___を埋めてみましょう。\n",
    "## URL内のArgsに各引数の詳細が書かれているので、確認しましょう。\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=___,\n",
    "    validation_split=0.2,\n",
    "    subset=___,\n",
    "    label_mode=___,\n",
    "    seed=1111,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=___,\n",
    "    validation_split=0.2,\n",
    "    subset=___,\n",
    "    label_mode=___,\n",
    "    seed=1111,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込めたら、Fashion-MNISTと同じように画像データがどうなっているかを確認します。  \n",
    "まず、データの形と、ラベルに何が存在するのかを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in val_data.take(1):\n",
    "    print(\"Image shape (batch, height, width, channel): \" + str(images.shape))\n",
    "    print(\"Label shape (batch, classes): \" + str(labels.shape))\n",
    "    print(\"Pet classes: \\n\" + str(val_data.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチサイズや画像のサイズが指定した数になっていることが確認できると思います。  \n",
    "また、Fashion-MNISTとは違い、今回のshapeには新たに画像のチャンネルが含まれています。  \n",
    "ここから、データセットの画像がグレースケールではなく、RGBのカラー画像であることがわかります。\n",
    "\n",
    "実際に画像を表示してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "def view_dataset():\n",
    "    for images, labels in val_data.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(\"label: \" + val_data.class_names[np.argmax(labels[i])])\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "view_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "犬や猫の犬種/猫種のカラー画像が表示できたかと思います。\n",
    "\n",
    "データセット全体の分布も見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = val_data.class_names\n",
    "left = range(0, len(class_names))\n",
    "height = np.zeros(len(class_names))\n",
    "for data in [train_data, val_data]:\n",
    "    for _, y in data:\n",
    "        height += np.sum(y, axis=0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(left, height, tick_label=class_names, align=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほとんどのデータが約200枚であることが確認できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、試しにこのデータを先ほどの学習済みモデル、classifierで判別してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in val_data.take(1):\n",
    "    for i in range(3):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        norm_images = images / 255\n",
    "        result = classifier.predict(norm_images)\n",
    "        predicted_class = np.argmax(result[i], axis=-1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\n",
    "            \"label: \" + val_data.class_names[np.argmax(labels[i])] +\n",
    "            ## <todo> ___を埋めてImageNetの予測ラベルを表示できるようにしてください\n",
    "            ## ヒント: ImageNetのlabelのlistはimagenet_labelsで定義されています\n",
    "            \"\\npredict: \" + ___[___]\n",
    "        )\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何回か繰り返して画像を確認してみてください。  \n",
    "すると、犬種/猫種を判別できるものと全く判別できないものがあると思います。  \n",
    "純粋な判別ミスもありますが、ここで理解してもらいたいことは、`classifier(mobilenet)が学習に使用しているImageNetデータセットのクラスに存在しないものは判別できない`ということです。\n",
    "\n",
    "今回だと\n",
    "- Havanese\n",
    "- Wheaten_terrier\n",
    "- American_Bulldog\n",
    "- American_Pit_Bull_Terrier\n",
    "- Bombay \n",
    "- Bengal\n",
    "- Rusian_Blue\n",
    "- Ragdoll\n",
    "- British_Shorthair\n",
    "- Ragdoll\n",
    "- Abysinian\n",
    "- Sphynx\n",
    "- ...\n",
    "\n",
    "あたりはImageNetに含まれていないので判別できません。    \n",
    "ImageNetにどういったクラスのものが存在するか興味がある方は、https://starpentagon.net/analytics/ilsvrc2012_class_image/\n",
    "でチェックしてみると良いです。(公式では現在検索できなくなっているようです。)\n",
    "\n",
    "こういったものも含めて犬種/猫種を判別できるようにするというのが、Transfer Learningの主目的となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "dataset apiを使ったおかげで、今回はデータのshapeを変える必要はなさそうです。\n",
    "\n",
    "[tf.keras.layers.experimental.preprocessing.Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling)を用いて正規化だけ行っておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> documentを参考に___を埋めてデータセットを正規化してください。\n",
    "norm_layer = tf.keras.layers.experimental.preprocessing.Rescaling(scale=___)\n",
    "norm_train_dataset = train_data.map(lambda x, y: (norm_layer(x), y))\n",
    "norm_val_dataset = val_data.map(lambda x, y: (norm_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構築\n",
    "データを用意することができたので、学習に使用するモデルを構築します。\n",
    "\n",
    "今回はTransfer Learningの有無による精度の差を確認したいので、  \n",
    "Fashion-MNISTで使った通常のCNNモデルと、Transfer Learningするモデルの二つを構築していきます。\n",
    "\n",
    "まず、CNNのモデルを定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "## <todo> データセットのクラス数分の値を___に入れてください。\n",
    "## ヒント: クラス名はデータセットのclass_names属性にあるので、そのlenをとることでクラス数分の値を取得できそうです。\n",
    "NUM_CLASSES =　___\n",
    "\n",
    "def cnn():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(32, kernel_size = (3,3), activation = \"relu\"))\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), activation = \"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), activation = \"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation = \"softmax\"))\n",
    "    return model\n",
    "\n",
    "cnn_model = cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Transfer Learningするモデルを構築します。\n",
    "特徴量ベクトルが取り出すことができる学習済みモデルを読み込みます。\n",
    "\n",
    "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
    "\n",
    "ここからurlをコピーして使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "def mobilenet_v2():\n",
    "    model = tf.keras.Sequential([\n",
    "        hub.KerasLayer(feature_vector_url, input_shape=IMAGE_SHAPE+(3,)),\n",
    "        ## <todo> クラス数分のpredictが出来るように最終層にDenseを追加してください。\n",
    "        ## ヒント: これまでと同じような形でDence層のメソッドを追加すれば良いです。出力層になるので、unit数と活性化関数に注意してください。\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "transfer_learning_model = mobilenet_v2()\n",
    "transfer_learning_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最終層につけたDenseがTrainableで、特徴量ベクトルの層がUntrainableになっていることが確認できるかと思います。  \n",
    "このTrainable部分を学習させることで、学習モデルにはない犬種/猫種も判別できるモデルにすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "モデルの構築ができたので、訓練を開始します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> ___を埋めて最適化関数がadam, 損失関数が'categorical_crossentropy'モデルをコンパイルできるようにしてください\n",
    "cnn_model.compile(\n",
    "  ___,\n",
    "  ___,\n",
    "  metrics=['categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <todo> 同じように___を埋めて最適化関数がadam, 損失関数が'categorical_crossentropyのモデルをコンパイルできるようにしてください\n",
    "transfer_learning_model.compile(\n",
    "  ___,\n",
    "  ___,\n",
    "  metrics=['categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\n",
    "を参考に、指標として使いたいlossとaccuracyをbatch毎(step毎)に記録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "        self.epoch_val_losses = []\n",
    "        self.epoch_val_acc = []\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_losses.append(logs['loss'])\n",
    "        self.batch_acc.append(logs['categorical_accuracy'])\n",
    "        self.model.reset_metrics()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ##  <todo> 対応するリストに'val_loss'と'val_categorical_accuracy'のlogを追加してください\n",
    "        ## ヒント: 一つ上のメソッド内を参考にしてください\n",
    "        \n",
    "        self.model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_stats_callback_cnn = CollectBatchStats()\n",
    "## <todo> ___に前処理後のtrainとvalidationのデータセットをいれて学習が開始できるようにしてください\n",
    "## ヒント: 前処理をしているセルを確認してみてください。\n",
    "cnn_model.fit(___, validation_data=___, epochs=5, callbacks=[batch_stats_callback_cnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_stats_callback_transfer_learning = CollectBatchStats()\n",
    "## <todo>  同じように___に前処理後のtrainとvalidationのデータセットをいれて学習が開始できるようにしてください\n",
    "## ヒント: 前処理をしているセルを確認してみてください。\n",
    "transfer_learning_model.fit(___, validation_data=___, epochs=5, callbacks=[batch_stats_callback_transfer_learning])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可視化\n",
    "訓練が終わったら、各モデルのlossとaccuracyの推移を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.suptitle(\"Training\", fontsize=15)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylim([0,4])\n",
    "plt.plot(batch_stats_callback_cnn.batch_losses, label=\"CNN model\")\n",
    "plt.plot(batch_stats_callback_transfer_learning.batch_losses, label=\"Transfer Learning model\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(batch_stats_callback_cnn.batch_acc, label=\"CNN model\")\n",
    "plt.plot(batch_stats_callback_transfer_learning.batch_acc, label=\"Transfer Learning model\")\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(bbox_to_anchor=[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.suptitle(\"Validation\", fontsize=15)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.plot(batch_stats_callback_cnn.epoch_val_losses, label=\"CNN model\")\n",
    "plt.plot(batch_stats_callback_transfer_learning.epoch_val_losses, label=\"Transfer Learning model\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.plot(batch_stats_callback_cnn.epoch_val_acc, label=\"CNN model\")\n",
    "plt.plot(batch_stats_callback_transfer_learning.epoch_val_acc, label=\"Transfer Learning model\")\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(bbox_to_anchor=[1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "両モデルの違いを確認できたでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各モデルの個別の予測結果も確認しましょう。  \n",
    "先程作ったview_datasetメソッドを改良して、ラベルの他にpredictも出力できるようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_dataset(model=None):\n",
    "    for images, labels in val_data.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            if not model:\n",
    "                plt.title(\"label: \" + val_data.class_names[np.argmax(labels[i])])\n",
    "            else:\n",
    "                norm_img = images / 255\n",
    "                result = model.predict(norm_img)\n",
    "                plt.title(\n",
    "                    \"label:\" + val_data.class_names[np.argmax(labels[i])] +\n",
    "                    ## <todo> ___を埋めてmodelがpredictした予測ラベルを表示できるようにしましょう\n",
    "                    ## 上の\"label:\"でやってくことが参考になります。predictした結果を渡すことに注意しましょう\n",
    "                    \"\\npredict:\" + ______[___(___[_])]\n",
    "                )\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "view_dataset(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "view_dataset(transfer_learning_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNetデータセットにない犬種/猫種も予測できたでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
