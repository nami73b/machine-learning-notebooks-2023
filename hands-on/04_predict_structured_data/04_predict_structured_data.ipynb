{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53de4e4",
   "metadata": {},
   "source": [
    "# Gradient Boosting Decision Tree (GBDT)\n",
    "\n",
    "このハンズオンでは、勾配ブースティング手法のライブラリであるLightGBMを使って、構造化データに対してのモデルを作成していきます。\n",
    "\n",
    "また勾配ブースティングでは、比較的簡単に予測結果の判断根拠も求めることができます。\n",
    "\n",
    "この利点としては\n",
    "- 予測の判断根拠自体が推論システムとしてあると何かと便利\n",
    "- 学習したモデルが一般的な常識/知見に基づいた特徴量であるか確認できる  \n",
    "\n",
    "などが挙げられます。\n",
    "\n",
    "このような、予測結果の判断根拠を得る手法についても紹介していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e435e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリ類のインストール\n",
    "!pip install lightgbm\n",
    "!pip install shap\n",
    "!pip install category_encoders\n",
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from io import BytesIO\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GoogleCloudStorageの接続\n",
    "project_id = 'hr-mixi'\n",
    "buclet_name = 'mixi_hands_on_data_2022'\n",
    "\n",
    "client = storage.Client(project_id)\n",
    "bucket = client.get_bucket(buclet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f8379",
   "metadata": {},
   "source": [
    "## データセットの読み込み\n",
    "今回は、実データを用いたタスクに挑戦していきます。  \n",
    "具体的には、過去数年の競輪のレースデータを使って、着順予測をしていきます。\n",
    "\n",
    "<font color='red'>**注意: 今回のデータは非公開データとなります。本研修外での利用はお控えください。**</font>\n",
    "\n",
    "GCSにデータを置いているので、取得してきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = 'training_data/race_data.csv'\n",
    "\n",
    "blob = bucket.blob(training_data_path)\n",
    "content = blob.download_as_string()\n",
    "df = pd.read_csv(BytesIO(content))\n",
    "\n",
    "# 着順のない選手をデータセットから取り除く\n",
    "df = df[~df['rank_number'].isnull()].reset_index(drop=True)\n",
    "df = df[df['rank_number'] != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889cf26",
   "metadata": {},
   "source": [
    "取得できたら、データを観察してみましょう。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1701aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    print(c, df.iloc[0][c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a85bc5-563b-47b7-a5b8-730cccbd37a1",
   "metadata": {},
   "source": [
    "**NOTE:** 今回は時間の都合上各カラムのデータをさらっと眺めるだけにしていますが、機械学習モデルを開発する上で、データへの理解度(ドメイン知識)は非常に重要な要素となってきます。  \n",
    "データのAnalysisだけでも時間をかける価値があるということを理解しておいてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e43c7f",
   "metadata": {},
   "source": [
    "## ラベルデータの作成\n",
    "次に、データからラベルを作成していきます。  \n",
    "今回は、rank_number　つまり着順を使用します。\n",
    "\n",
    "このとき、着順をそのままラベルに使用すると、タスクは多クラス分類となります。  \n",
    "多クラス分類になると、それぞれのクラスを独立したものとして扱うことになりますが、1着と2着などを別クラスとして扱うことは正しいでしょうか。  \n",
    "例えば別の考え方として、ラベルを`3着以内orNot`や`1着orNot`に変換する方法も考えられます。  \n",
    "このようにした場合、今回のタスクは２値分類タスクとなります。  \n",
    "また、`1着orNot`にした場合、出力は確率になるので、その確率が高い順と考えると、結果的に着順も予測できることになります。  \n",
    "ラベルをどのように扱えばより良いかは自分で考える必要があるので、このようなドメイン知識が重要になってきます。  \n",
    "今回はそのままの着順予測と1着orNotの2値分類を作っていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849c74e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encord_rank_order(rank_number):\n",
    "    # LightGBMも多クラス分類は0から始まるラベルが求められるが\n",
    "    # 着順は１〜９になっているため、0~8に修正する\n",
    "    return rank_number -1\n",
    "\n",
    "## <TODO> ___を埋めて多クラス(9クラス)分類のラベルを作ってください。\n",
    "## ヒント: rank_numberには1~9の着順が表形式で入っており、それがapplyの中身で順に処理されていきます。また、applyの第一引数はfuncです\n",
    "rank_number = df['rank_number'].apply(___)\n",
    "\n",
    "## <TODO> ___を埋めて独自ラベルとして1着orNotの2値分類のラベルを作ってください。\n",
    "## ヒント: (無名関数)lambdaの部分は'lambda 引数: (条件がTrueの時の値) if (条件) else (条件がFalseの時の値)'となっています。\n",
    "your_target = df['rank_number'].apply(lambda x: 1 if ______ else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47b0d2",
   "metadata": {},
   "source": [
    "## 学習/テスト用データセットの分割\n",
    "\n",
    "テストデータは日付で2021/01/01以降のレースを対象とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4329cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_date = 20210101\n",
    "\n",
    "train_index = df[df['event_date'] < train_test_split_date].index\n",
    "test_index = df[df['event_date'] >= train_test_split_date].index\n",
    "\n",
    "df_train = df.loc[train_index].reset_index(drop=True)\n",
    "rank_order_train = rank_number[train_index].values\n",
    "your_target_train = your_target[train_index]\n",
    "\n",
    "df_test = df.loc[test_index].reset_index(drop=True)\n",
    "rank_order_test = rank_number[test_index].values\n",
    "your_target_test = your_target[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9695bca",
   "metadata": {},
   "source": [
    "## 前処理\n",
    "前処理では一般的に以下のような処理を行います。  \n",
    "\n",
    "- 文字列やカテゴリカルなデータを数値やベクトルに変換(LabelEncording, OneHotEncordingなど)  \n",
    "- アルゴリズムが学習しやすいように変換(欠損値処理、正規化など)  \n",
    "- 組み合わせや集計処理によって新しい特徴量を作成  \n",
    "など\n",
    "\n",
    "前処理コードを学習と予測用で分けているのは、予測時に学習時のラベルエンコーディングのIDのマップと同じようにIDを振り分ける必要がある等、学習時と同様のデータの変換をするように予測用の前処理コードに記載する必要があるためです。  \n",
    "今回もタスクに必要な前処理を行っていきます。\n",
    "\n",
    "**\\<チャレンジ\\>**  \n",
    "余裕があれば、特徴量の変換や集計で新しい特徴量を作成してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc74bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習に使用しないカラムのリスト\n",
    "unuse_feature_list = [\n",
    "    'event_date', 'race_start_date_time', 'player_number', 'name', 'rank_number'\n",
    "]\n",
    "\n",
    "# レース内の集計をする特徴量\n",
    "stat_columns = [\n",
    "    'gear_ratio', 'age', 'prize', 'rank', 'total_win_count',\n",
    "    'average_race_point', 'place_rate', 'nige_count',\n",
    "    'sashi_count', 'makuri_count', 'mark_count', 'standing_count',\n",
    "    'back_count'\n",
    "]\n",
    "\n",
    "# カテゴリカル特徴量のリスト\n",
    "categorical_feature_list = [\n",
    "    'velodrome_code', 'program_name', 'grade', 'group', 'born_prefecture', 'leg_type'\n",
    "]\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "def training_preprocessing(df):\n",
    "    # カテゴリカル変数の処理\n",
    "    # LightGBMでは、ラベルエンコーディング(カテゴリをintでID付け)して、typeをcategoryに変換すればライブラリが上手く扱ってくれる\n",
    "    categorical_encorder = ce.OrdinalEncoder(cols=categorical_feature_list, handle_unknown='impute')\n",
    "    \n",
    "    df = categorical_encorder.fit_transform(df)\n",
    "    for c in categorical_feature_list:\n",
    "        df[c] = df[c].astype('category')\n",
    "        \n",
    "    # レース内での平均値の特徴量の作成\n",
    "    race_mean = df.groupby(['event_date', 'velodrome_code', 'race_number'])[stat_columns].mean()\n",
    "\n",
    "    race_mean = race_mean.rename(columns= {x: x+'_mean' for x in race_mean.columns})\n",
    "    df = pd.merge(df, race_mean, how='left', on=['event_date', 'velodrome_code', 'race_number'])\n",
    "    \n",
    "    # レース内での中央値の特徴量の作成\n",
    "    race_median = df.groupby(['event_date', 'velodrome_code', 'race_number'])[stat_columns].median()\n",
    "\n",
    "    race_median = race_median.rename(columns= {x: x+'_median' for x in race_median.columns})\n",
    "    df = pd.merge(df, race_median, how='left', on=['event_date', 'velodrome_code', 'race_number'])\n",
    "    \n",
    "    # 不要なカラムを削除する\n",
    "    df = df.drop(unuse_feature_list, axis=1)\n",
    "\n",
    "    return df, categorical_encorder\n",
    "\n",
    "\n",
    "def prediction_preprocessing(df, categorical_encorder):\n",
    "    # カテゴリカル変数の処理\n",
    "    df = categorical_encorder.transform(df)\n",
    "    for c in categorical_feature_list:\n",
    "        df[c] = df[c].astype('category')\n",
    "        \n",
    "    # レース内での平均値の特徴量の作成\n",
    "    race_mean = df.groupby(['event_date', 'velodrome_code', 'race_number'])[stat_columns].mean()\n",
    "\n",
    "    race_mean = race_mean.rename(columns= {x: x+'_mean' for x in race_mean.columns})\n",
    "    df = pd.merge(df, race_mean, how='left', on=['event_date', 'velodrome_code', 'race_number'])\n",
    "    \n",
    "    # レース内での中央値の特徴量の作成\n",
    "    race_median = df.groupby(['event_date', 'velodrome_code', 'race_number'])[stat_columns].median()\n",
    "\n",
    "    race_median = race_median.rename(columns= {x: x+'_median' for x in race_median.columns})\n",
    "    df = pd.merge(df, race_median, how='left', on=['event_date', 'velodrome_code', 'race_number'])\n",
    "    \n",
    "    # 不要なカラムを削除する\n",
    "    df = df.drop(unuse_feature_list, axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9aa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproessed_df_train, categorical_encorder = training_preprocessing(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproessed_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30e269",
   "metadata": {},
   "source": [
    "## 学習データから検証データを分割\n",
    "\n",
    "学習用と検証用は0.8:0.2で分割しています。  \n",
    "検証用データは、モデル学習時のtest_lossの計算のほか、  \n",
    "パラメーターの自動チューニング時のloss指標の計算に使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rate = 0.2\n",
    "\n",
    "train_val_split_point = int(len(df_train)*(1-val_rate))\n",
    "\n",
    "df_val = preproessed_df_train.iloc[train_val_split_point:].reset_index(drop=True)\n",
    "df_train = preproessed_df_train.iloc[:train_val_split_point].reset_index(drop=True)\n",
    "\n",
    "rank_order_val = rank_order_train[train_val_split_point:]\n",
    "rank_order_train = rank_order_train[:train_val_split_point]\n",
    "\n",
    "your_target_val = your_target_train[train_val_split_point:]\n",
    "your_target_train = your_target_train[:train_val_split_point]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd24e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学習\n",
    "\n",
    "準備が整ったので、モデルの学習をさせていきます。\n",
    "\n",
    "主要なLightGBMのパラメータを下記に記載します。\n",
    "\n",
    "```\n",
    "- 出力形式に関する要素\n",
    "    - objective\n",
    "        - regression: 回帰\n",
    "        - binary: 二値分類\n",
    "        - multiclass: 多クラス分類\n",
    "    - metric\n",
    "        - 回帰\n",
    "            - mae: mean absolute error・平均絶対誤差\n",
    "            - mse: mean squared error平均2乗誤差\n",
    "        - 二値分類\n",
    "            - binary_logloss:　クロスエントロピー\n",
    "            - binary_error: 正解率\n",
    "        - 多クラス分類\n",
    "            - multi_logloss: softmax\n",
    "            - multi_error: 正解率\n",
    "- モデル構造に関する要素\n",
    "    - learning_rate: 学習率 Default=0.1 0以上\n",
    "    - num_iterations: 木の数\n",
    "    - num_leaves: 葉(条件の数)\n",
    "```\n",
    "\n",
    "公式リファレンス　https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "  \n",
    "**\\<チャレンジ\\>** \n",
    "余裕が有れば、lgb_paramsに任意のパラメータを追加して、モデルの精度の変化を観察してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac248de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 着順の多クラス分類モデルの学習\n",
    "\n",
    "lgb_train = lgb.Dataset(df_train, rank_order_train)\n",
    "lgb_test = lgb.Dataset(df_val, rank_order_val, reference=lgb_train)\n",
    "\n",
    "## <TODO> lgb_paramsのobjectiveとmetricを正しい値で埋めてください\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 1000,\n",
    "    'num_class': 9,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'objective': '______',\n",
    "    'metric': '______',\n",
    "}\n",
    "\n",
    "booster_rank_number = lgb.train(\n",
    "    lgb_params, lgb_train, valid_sets=lgb_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812b417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# オリジナルターゲット（2値分類）のモデルの学習\n",
    "lgb_train = lgb.Dataset(df_train, your_target_train)\n",
    "lgb_test = lgb.Dataset(df_val, your_target_val, reference=lgb_train)\n",
    "\n",
    "## <TODO> lgb_paramsのobjectiveとmetricを正しい値で埋めてください\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 1000,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'objective': '_____',\n",
    "    'metric': '_____',\n",
    "}\n",
    "\n",
    "booster_your_target = lgb.train(\n",
    "    lgb_params, lgb_train, valid_sets=lgb_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8a6f2-e3fd-4487-b07d-ed41368c8bdc",
   "metadata": {},
   "source": [
    "学習が始まって、経過が確認できるでしょうか"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe44d1",
   "metadata": {},
   "source": [
    "## モデルの判断根拠: Importance\n",
    "\n",
    "学習が完了したら、特徴量毎のImportanceを確認してみましょう。  \n",
    "feature_importanceメソッドでモデルにおける特徴量の重要度を得られます。  \n",
    "重要度の指標:\n",
    "- split: 決定木の分岐を使用した数  \n",
    "- gain: その特徴量が使用する分岐からの目的関数の減少  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの前処理の実行\n",
    "preprocessed_df_test = prediction_preprocessing(df_test, categorical_encorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8ac45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split\n",
    "importance = pd.DataFrame(\n",
    "    booster_your_target.feature_importance(importance_type = 'split'),\n",
    "    index=preproessed_df_train.columns,\n",
    "    columns=['importance']\n",
    ")\n",
    "importance.sort_values(['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781abb69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gain\n",
    "importance = pd.DataFrame(\n",
    "    booster_your_target.feature_importance(importance_type = 'gain'),\n",
    "    index=preproessed_df_train.columns,\n",
    "    columns=['importance']\n",
    ")\n",
    "importance.sort_values(['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d878279",
   "metadata": {},
   "source": [
    "## モデルの判断根拠: SHAP\n",
    "また、SHAPを用いることでも、特徴量がモデル/予測に対してどのような影響を与えたかを計測できます。  \n",
    "試してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d81c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBMは決定木アルゴリズムなのでTreeExplainerを使う\n",
    "# NNモデルでDeepExplainerを使うと今回のようなテーブルデータだけでなく、画像データに対しても適用することができる\n",
    "\n",
    "explainer = shap.TreeExplainer(booster_your_target, feature_perturbation = \"tree_path_dependent\")\n",
    "shap_values = explainer.shap_values(preprocessed_df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の貢献度をプロット\n",
    "shap.summary_plot(shap_values, preprocessed_df_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a895c5",
   "metadata": {},
   "source": [
    "### 予測ごとの判断根拠\n",
    "shap_valuesには各予測に対しての各特徴量の貢献度が格納されています。  \n",
    "これを使うことで、例えばあるレースの結果の予測は、この特徴量が強く影響しているためという表現ができるようになります。  \n",
    "\n",
    "検証用データの0番目の予測結果を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "shap_v = pd.DataFrame(shap_values[1], columns=preprocessed_df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5088e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果に対しでpositiveな影響を与えている特徴量\n",
    "shap_v.iloc[idx].sort_values(ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果に対しでnegativeな影響を与えている特徴量\n",
    "shap_v.iloc[idx].sort_values(ascending=True).iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455da7b5",
   "metadata": {},
   "source": [
    "## 精度検証\n",
    "\n",
    "特徴量の貢献度はあらかた調べられたので、締め括りとしてこのモデルの精度の評価をしましょう。\n",
    "今回の精度指標は、  \n",
    "`レース内で最も1着である確率である確率が高いと評価された選手が実際に1着であった確率`  \n",
    "と設定します。\n",
    "\n",
    "データは１行で1選手を表現しているため、1レース単位は複数行を集約する必要があります。  \n",
    "groupbyを使ってレースごとのindexを取得していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_groups = df_test.groupby(['event_date', 'velodrome_code', 'race_number']).groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87325e20",
   "metadata": {},
   "source": [
    "### 着順の多クラス分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f283cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果の取得\n",
    "rank_number_prediction_result = booster_rank_number.predict(preprocessed_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果の0番目の出力\n",
    "# 9つの要素がありそれぞれが各ラベルの確率を表現しています、つまり合計は1になります\n",
    "print(rank_number_prediction_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# レースごとの出力値の0番目(1着と推定した確率)がもっとも大きい(np.argmax)選手の実際の着順が1着だった数/ レースの数\n",
    "[\n",
    "    df_test.iloc[idx[np.argmax(\n",
    "        [\n",
    "            res[0] for res in rank_number_prediction_result[idx]\n",
    "        ]\n",
    "    )]]['rank_number']\n",
    "    for race, idx in race_groups.items()\n",
    "].count(1) / len(race_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b96eb",
   "metadata": {},
   "source": [
    "### '1着 or Not'の2値分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_target_prediction_result = booster_your_target.predict(preprocessed_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_target_prediction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61781e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# レースごとの出力値がもっとも大きい(np.argmax)選手の実際の着順が1着だった数/ レースの数\n",
    "[\n",
    "    df_test.iloc[idx[np.argmax(your_target_prediction_result[idx])]]['rank_number']\n",
    "    for race, idx in race_groups.items()\n",
    "].count(1) / len(race_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9f85b-f892-4ed3-8435-d670931e8187",
   "metadata": {},
   "source": [
    "精度はどうでしょうか？  \n",
    "着順の多クラス分類と、'1着orNot'の2値分類モデルでどれくらい差があったでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b7299-aca1-4dec-ab8c-e32a9e0ea571",
   "metadata": {},
   "source": [
    "========================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803da971",
   "metadata": {},
   "source": [
    "# やってみよう: リアルタイムの競輪レース予測\n",
    "\n",
    "ここまでで、GBDTのハンズオンは一通り終了です。  \n",
    "ですが、折角競輪の予測を作ったので、実際に今日のレースを予測してみましょう！\n",
    "\n",
    "GCSに本日のレースデータのcsvを作成してあります。  \n",
    "このデータに対する予測結果を作成して、今日の全レースに対する予測を作成していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本日のレースデータをGCSから取得\n",
    "prediction_data_path = 'prediction_data/race_data.csv'\n",
    "blob = bucket.blob(prediction_data_path)\n",
    "content = blob.download_as_string()\n",
    "prediction_df = pd.read_csv(BytesIO(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3324666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupsの作成\n",
    "prediction_race_groups = prediction_df.groupby(['event_date', 'velodrome_code', 'race_number']).groups\n",
    "\n",
    "# 前処理の実行\n",
    "preprocessed_prediction_df = prediction_preprocessing(prediction_df, categorical_encorder)\n",
    "\n",
    "# 予測結果の作成\n",
    "# ここでは'1着orNotモデル'を使用しています。別のモデルを使いたい場合は、変更してください。\n",
    "today_prediction_result = booster_your_target.predict(preprocessed_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42492b-6db3-47ce-a982-90bd666a63c8",
   "metadata": {},
   "source": [
    "できたら、今日のレースが予想とマッチするかみていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f796a7",
   "metadata": {},
   "source": [
    "### 予測結果の確認\n",
    "まず、今日の全レースの予想を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "velodrome_code = {\n",
    "    11: '函館競輪場', \n",
    "    12: '青森競輪場', \n",
    "    13: 'いわき平競輪場', \n",
    "    21: '弥彦競輪場', \n",
    "    22: '前橋競輪場', \n",
    "    23: '取手競輪場', \n",
    "    24: '宇都宮競輪場', \n",
    "    25: '大宮競輪場', \n",
    "    26: '西武園競輪場', \n",
    "    27: '京王閣競輪場', \n",
    "    28: '立川競輪場', \n",
    "    31: '松戸競輪場', \n",
    "    32: '千葉競輪場', \n",
    "    33: '花月園競輪場', \n",
    "    34: '川崎競輪場', \n",
    "    35: '平塚競輪場', \n",
    "    36: '小田原競輪場', \n",
    "    37: '伊東競輪場', \n",
    "    38: '静岡競輪場', \n",
    "    41: '一宮競輪場', \n",
    "    42: '名古屋競輪場', \n",
    "    43: '岐阜競輪場', \n",
    "    44: '大垣競輪場', \n",
    "    45: '豊橋競輪場', \n",
    "    46: '富山競輪場', \n",
    "    47: '松阪競輪場', \n",
    "    48: '四日市競輪場', \n",
    "    51: '福井競輪場', \n",
    "    52: '大津競輪場', \n",
    "    53: '奈良競輪場', \n",
    "    54: '向日町競輪場', \n",
    "    55: '和歌山競輪場', \n",
    "    56: '岸和田競輪場', \n",
    "    61: '玉野競輪場', \n",
    "    62: '広島競輪場', \n",
    "    63: '防府競輪場', \n",
    "    71: '高松競輪場', \n",
    "    72: '観音寺競輪場', \n",
    "    73: '小松島競輪場', \n",
    "    74: '高知競輪場', \n",
    "    75: '松山競輪場', \n",
    "    81: '小倉競輪場', \n",
    "    83: '久留米競輪場', \n",
    "    84: '武雄競輪場', \n",
    "    85: '佐世保競輪場', \n",
    "    86: '別府競輪場',\n",
    "    87: '熊本競輪場', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac717022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for race, idx in prediction_race_groups.items():\n",
    "    print('会場: ', velodrome_code[race[1]])\n",
    "    print('レース番号: ', race[2])\n",
    "    \n",
    "    # 1レース分の予測結果を正規化(合計1に変換)して確率の形にしています\n",
    "    normed_result = today_prediction_result[idx] / sum(today_prediction_result[idx])\n",
    "    \n",
    "    for entry_num, prob in zip(prediction_df.iloc[idx]['entry_number'].values, normed_result):\n",
    "        print(entry_num, '番: ', round(prob, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e8704-e4a2-4b87-a729-4c7be7a560b1",
   "metadata": {},
   "source": [
    "予測結果を出力できたら、その予測が当たってるかどうかをTipstarで確認してみましょう。  \n",
    "https://tipstar.com/keirin/channels  \n",
    "過去のレースは既に結果が出ているので、答え合わせができるかと思います。\n",
    "\n",
    "また競輪は比較的高頻度で開催されているので、今の時間帯でもレース開始時間の近いものがあると思います。  \n",
    "上記のURLから、直近のレースを選択してください。\n",
    "そして、そのレースの予測を今一度確認してみてください。    \n",
    "確認できたら、予測とレース結果が同じになることをリアルタイムで確認していきます。  \n",
    "Tipstarにレースの映像があるので、それを見ながら予想した選手を応援しましょう！"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
