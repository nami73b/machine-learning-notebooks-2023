{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53de4e4",
   "metadata": {},
   "source": [
    "# Gradient Boosting Decision Tree (GBDT)\n",
    "\n",
    "このハンズオンでは、勾配ブースティング手法のライブラリであるLightGBMを使って、構造化(テーブル)データに対してのモデルを作成していきます。\n",
    "\n",
    "また勾配ブースティングでは、比較的簡単に予測結果の判断根拠も求めることができます。\n",
    "\n",
    "この利点としては\n",
    "- 予測の判断根拠自体が推論システムとしてあると何かと便利\n",
    "- 学習したモデルが一般的な常識/知見に基づいた特徴量であるか確認できる  \n",
    "\n",
    "などが挙げられます。\n",
    "\n",
    "このような、予測結果の判断根拠を得る手法についても紹介していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e435e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリ類のインストール\n",
    "# 2回目以降は実行不要\n",
    "!pip install lightgbm shap category_encoders storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from io import BytesIO\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GoogleCloudStorageの接続\n",
    "project_id = 'hr-mixi'\n",
    "buclet_name = 'mixi-ml-handson-2023'\n",
    "\n",
    "client = storage.Client(project_id)\n",
    "bucket = client.get_bucket(buclet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f8379",
   "metadata": {},
   "source": [
    "## データセットの読み込み\n",
    "今回は、実データを用いたタスクに挑戦していきます。  \n",
    "具体的には、過去数年の競輪のレースデータを使って、着順予測をしていきます。\n",
    "\n",
    "<font color='red'>**注意: 今回のデータは非公開データとなります。本研修外での利用はお控えください。**</font>\n",
    "\n",
    "GCSにデータを置いているので、取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = '05_predict_structured_data/training_data/race_data.csv'\n",
    "\n",
    "blob = bucket.blob(training_data_path)\n",
    "content = blob.download_as_string()\n",
    "df = pd.read_csv(BytesIO(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889cf26",
   "metadata": {},
   "source": [
    "取得できたら、データを観察してみましょう。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd846b6-5f2d-4ce2-8439-6dae429dd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データサイズの確認\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7c6eb-6cda-48c3-b369-dc677be41c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの機関の確認\n",
    "'日付開始日: {}, 日付終了日: {}'.format(df['KaisaiDate'].max(), df['KaisaiDate'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32ea24-ddc3-4a6f-9c18-c994eccec08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの統計量の確認\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1701aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0行目のデータの内容\n",
    "for c in df.columns:\n",
    "    print(c, df.iloc[0][c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a85bc5-563b-47b7-a5b8-730cccbd37a1",
   "metadata": {},
   "source": [
    "**NOTE:** 今回は時間の都合上各カラムのデータをさらっと眺めるだけにしていますが、機械学習モデルを開発する上で、データへの理解度(ドメイン知識)は非常に重要な要素となってきます。  \n",
    "データのAnalysisだけでも時間をかける価値があるということを理解しておいてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e43c7f",
   "metadata": {},
   "source": [
    "## ターゲットデータの作成\n",
    "次に、データからラベルを作成していきます。  \n",
    "今回は、KakuteiJyuniつまり着順を使用します。\n",
    "\n",
    "このとき、着順をそのままラベルに使用する場合、着順それぞれを1クラスとした多クラス分類となります。  \n",
    "多クラス分類になると、それぞれのクラスを独立したものとして扱うことになりますが、1着と2着などを別クラスとして扱うことは正しいでしょうか。  \n",
    "\n",
    "例えば工夫した考え方として、ラベルを`3着以内orNot`や`1着orNot`に変換する方法も考えられます。  \n",
    "このようにした場合、今回のタスクは２値分類タスクとなります。  \n",
    "また、`1着orNot`にした場合、出力は確率になるので、その確率が高い順と考えると、結果的に着順も予測できることになります。  \n",
    "\n",
    "ラベルをどのように扱えばより良いかは自分で考える必要があるので、このようなドメイン知識が重要になってきます。  \n",
    "\n",
    "初回はそのまま着順をそのままラベルに使用した多クラス分類モデルを作成します\n",
    "\n",
    "<Challenge>\n",
    "後ほど、各々ここのターゲットを各自変えて再度モデルを学習し直してもらいます   \n",
    "    \n",
    "- ヒント: メモリ上に実行した引数が残ってしまっていると意図した動作をしないケースが発生するので、モデルを作り直す場合はカーネルリセットをお勧めします\n",
    "    \n",
    "サンプル\n",
    "・1着orNotの2値分類\n",
    "```\n",
    "target = df['KakuteiJyuni'].apply(lambda x: 1 if x == 1 else 0)\n",
    "```\n",
    "    \n",
    "・3着以内orNotの2値分類\n",
    "```\n",
    "target = df['KakuteiJyuni'].apply(lambda x: 1 if x <= 3 else 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30146d22-1d21-43ac-b2dc-4a407a14e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMのマルチクラス分類のラベルは0から始まる連番である必要があるので、\n",
    "# 1着 → 0, 2着 → 1　...のように変換します\n",
    "target = df['KakuteiJyuni'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47b0d2",
   "metadata": {},
   "source": [
    "## 学習/テスト用データセットの分割\n",
    "\n",
    "テストデータは日付で2023/01/01以降のレースを対象とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4329cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_date = 20230101\n",
    "\n",
    "train_index = df[df['KaisaiDate'] < train_test_split_date].index\n",
    "test_index = df[df['KaisaiDate'] >= train_test_split_date].index\n",
    "\n",
    "df_train = df.loc[train_index].reset_index(drop=True)\n",
    "target_train = target[train_index].values\n",
    "\n",
    "df_test = df.loc[test_index].reset_index(drop=True)\n",
    "target_test = target[test_index].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9695bca",
   "metadata": {},
   "source": [
    "## 前処理\n",
    "前処理では一般的に以下のような処理を行います。  \n",
    "\n",
    "- 文字列やカテゴリカルなデータを数値やベクトルに変換(LabelEncording, OneHotEncordingなど)  \n",
    "- アルゴリズムが学習しやすいように変換(欠損値処理、正規化など)  \n",
    "- 組み合わせや集計処理によって新しい特徴量を作成  \n",
    "など\n",
    "\n",
    "前処理コードを学習と予測用で分けているのは、予測時に学習時のラベルエンコーディングのIDのマップと同じようにIDを振り分ける必要がある等、学習時と同様のデータの変換をするように予測用の前処理コードに記載する必要があるためです。  \n",
    "今回もタスクに必要な前処理を行っていきます。\n",
    "\n",
    "**\\<チャレンジ\\>**  \n",
    "余裕があれば、特徴量の変換や集計で新しい特徴量を作成してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc74bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習に使用しないカラムのリスト\n",
    "# ・結果データ・選手/レースを識別してしまうデータを取り除く\n",
    "unuse_feature_list = [\n",
    "    'RaceId', 'KaisaiDate', 'SenshuCD', 'Kimari', 'IJyoCD', 'KakuteiJyuni', 'AgariTime', 'ChakusaCD', 'StdGet', 'JanGet', 'HomeGet', 'BackGet',\n",
    "    'Hondai', 'GaiteiName', 'HassoTime', 'HassoTimeOld1', 'HassoTimeOld2', 'HassoTimeOld3'\n",
    "]\n",
    "\n",
    "# レース内の集計をする特徴量\n",
    "stat_columns = [\n",
    "    'Age', 'Gear', 'Graduate', 'RaceRating', 'Shokin'\n",
    "]\n",
    "\n",
    "# カテゴリカル特徴量のリスト\n",
    "categorical_feature_list = [\n",
    "    # 今回レースに関する特徴量\n",
    "    'JyoCD', 'KaisaiGrade', 'Kyori',\n",
    "    # 選手に関する特徴量\n",
    "    'Kyu', 'Han', 'Fuken', 'Kyakushitu',\n",
    "    # 1走前レースに関する特徴量\n",
    "    'JyoCDOld1', 'RaceNumOld1', 'HondaiOld1', 'GaiteiNameOld1','KyoriOld1',\n",
    "    # 1走前選手に関する特徴量\n",
    "    'SyabanOld1', 'ChakusaCDOld1', 'StdGetOld1', 'JanGetOld1', 'HomeGetOld1', 'BackGetOld1',\n",
    "    # 2走前レースに関する特徴量\n",
    "    'JyoCDOld2', 'RaceNumOld2', 'HondaiOld2', 'GaiteiNameOld2','KyoriOld2',\n",
    "    # 2走前選手に関する特徴量\n",
    "    'SyabanOld2', 'ChakusaCDOld2', 'StdGetOld2', 'JanGetOld2', 'HomeGetOld2', 'BackGetOld2',\n",
    "    # 3走前レースに関する特徴量\n",
    "    'JyoCDOld3', 'RaceNumOld3', 'HondaiOld3', 'GaiteiNameOld3','KyoriOld3',\n",
    "    # 3走前選手に関する特徴量\n",
    "    'SyabanOld3', 'ChakusaCDOld3', 'StdGetOld3', 'JanGetOld3', 'HomeGetOld3', 'BackGetOld3',\n",
    "    # 決まり手に関する特徴量\n",
    "    'KimariOld1', 'KimariOld2', 'KimariOld3'\n",
    "]\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "def training_preprocessing(df):\n",
    "    # カテゴリカル変数の処理\n",
    "    # LightGBMでは、ラベルエンコーディング(カテゴリをintでID付け)して、typeをcategoryに変換すればライブラリが上手く扱ってくれる\n",
    "    categorical_encorder = ce.OrdinalEncoder(cols=categorical_feature_list, handle_unknown='impute')\n",
    "    \n",
    "    df = categorical_encorder.fit_transform(df)\n",
    "        \n",
    "    # レース内での平均値の特徴量の作成\n",
    "    race_mean = df.groupby(['RaceId'])[stat_columns].mean()\n",
    "\n",
    "    race_mean = race_mean.rename(columns= {x: x+'Mean' for x in race_mean.columns})\n",
    "    df = pd.merge(df, race_mean, how='left', on=['RaceId'])\n",
    "    \n",
    "    # レース内での中央値の特徴量の作成\n",
    "    race_median = df.groupby(['RaceId'])[stat_columns].median()\n",
    "\n",
    "    race_median = race_median.rename(columns= {x: x+'Median' for x in race_median.columns})\n",
    "    df = pd.merge(df, race_median, how='left', on=['RaceId'])\n",
    "    \n",
    "    # 不要なカラムを削除する\n",
    "    df = df.drop(unuse_feature_list, axis=1)\n",
    "\n",
    "    return df, categorical_encorder\n",
    "\n",
    "\n",
    "def prediction_preprocessing(df, categorical_encorder):\n",
    "    # カテゴリカル変数の処理\n",
    "    df = categorical_encorder.transform(df)\n",
    "        \n",
    "    # レース内での平均値の特徴量の作成\n",
    "    race_mean = df.groupby(['RaceId'])[stat_columns].mean()\n",
    "\n",
    "    race_mean = race_mean.rename(columns= {x: x+'Mean' for x in race_mean.columns})\n",
    "    df = pd.merge(df, race_mean, how='left', on=['RaceId'])\n",
    "    \n",
    "    # レース内での中央値の特徴量の作成\n",
    "    race_median = df.groupby(['RaceId'])[stat_columns].median()\n",
    "\n",
    "    race_median = race_median.rename(columns= {x: x+'Median' for x in race_median.columns})\n",
    "    df = pd.merge(df, race_median, how='left', on=['RaceId'])\n",
    "    \n",
    "    # 不要なカラムを削除する\n",
    "    df = df.drop(unuse_feature_list, axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9aa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理の実行には1分程度かかります\n",
    "preproessed_df_train, categorical_encorder = training_preprocessing(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproessed_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30e269",
   "metadata": {},
   "source": [
    "## 学習データから検証データを分割\n",
    "\n",
    "学習用と検証用は8:2で分割しています。  \n",
    "検証用データは、モデル学習時のtest_lossの計算のほか、  \n",
    "パラメーターの自動チューニング時のloss指標の計算に使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rate = 0.2\n",
    "\n",
    "train_val_split_point = int(len(df_train)*(1-val_rate))\n",
    "\n",
    "preproessed_df_val = preproessed_df_train.iloc[train_val_split_point:].reset_index(drop=True)\n",
    "preproessed_df_train = preproessed_df_train.iloc[:train_val_split_point].reset_index(drop=True)\n",
    "\n",
    "target_val = target_train[train_val_split_point:]\n",
    "target_train = target_train[:train_val_split_point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd24e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学習\n",
    "\n",
    "準備が整ったので、モデルの学習をさせていきます。\n",
    "\n",
    "主要なLightGBMのパラメータを下記の通りです。\n",
    "\n",
    "```\n",
    "- 出力形式に関する要素\n",
    "    - objective\n",
    "        - regression: 回帰\n",
    "        - binary: 二値分類\n",
    "        - multiclass: 多クラス分類\n",
    "    - metric\n",
    "        - 回帰\n",
    "            - mae: mean absolute error: 平均絶対誤差\n",
    "            - mse: mean squared error: 平均2乗誤差\n",
    "        - 二値分類\n",
    "            - binary_logloss:　クロスエントロピー\n",
    "            - binary_error: 正解率\n",
    "        - 多クラス分類\n",
    "            - multi_logloss: softmax\n",
    "            - multi_error: 正解率\n",
    "- モデル構造に関する要素\n",
    "    - learning_rate: 学習率 Default=0.1 0以上\n",
    "    - num_iterations: 木の数\n",
    "    - num_leaves: 葉(条件の数)\n",
    "    - max_depth: 木の深さの最大値\n",
    "```\n",
    "\n",
    "公式リファレンス　https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "  \n",
    "**\\<チャレンジ\\>** \n",
    "余裕が有れば、lgb_paramsに任意のパラメータを追加して、モデルの精度の変化を観察してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac248de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 着順の多クラス分類モデルの学習\n",
    "\n",
    "lgb_train = lgb.Dataset(preproessed_df_train, target_train)\n",
    "lgb_test = lgb.Dataset(preproessed_df_val, target_val, reference=lgb_train)\n",
    "\n",
    "## <TODO> lgb_paramsのobjectiveとmetricとnum_classを正しい値で埋めてください\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 1000,\n",
    "    'num_class': ______,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'objective': '______',\n",
    "    'metric': '______',\n",
    "}\n",
    "\n",
    "booster = lgb.train(\n",
    "    lgb_params, lgb_train, valid_sets=lgb_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8a6f2-e3fd-4487-b07d-ed41368c8bdc",
   "metadata": {},
   "source": [
    "学習が始まって、経過が確認できるでしょうか"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe44d1",
   "metadata": {},
   "source": [
    "## モデルの判断根拠: Importance\n",
    "\n",
    "学習が完了したら、特徴量毎のImportanceを確認してみましょう。  \n",
    "feature_importanceメソッドでモデルにおける特徴量の重要度を得られます。  \n",
    "重要度の指標:\n",
    "- split: 決定木の分岐を使用した数  \n",
    "- gain: その特徴量が使用する分岐からの目的関数の減少  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの前処理の実行\n",
    "preprocessed_df_test = prediction_preprocessing(df_test, categorical_encorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8ac45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split\n",
    "importance = pd.DataFrame(\n",
    "    booster.feature_importance(importance_type = 'split'),\n",
    "    index=preproessed_df_train.columns,\n",
    "    columns=['importance']\n",
    ")\n",
    "importance.sort_values(['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781abb69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gain\n",
    "importance = pd.DataFrame(\n",
    "    booster.feature_importance(importance_type = 'gain'),\n",
    "    index=preproessed_df_train.columns,\n",
    "    columns=['importance']\n",
    ")\n",
    "importance.sort_values(['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d878279",
   "metadata": {},
   "source": [
    "## モデルの判断根拠: SHAP\n",
    "また、SHAPを用いることでも、特徴量がモデル/予測に対してどのような影響を与えたかを計測できます。  \n",
    "試してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d81c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBMは決定木アルゴリズムなのでTreeExplainerを使います\n",
    "# NNモデルでDeepExplainerを使うと今回のようなテーブルデータだけでなく、画像データに対しても適用することができます\n",
    "# ２分程度時間がかかります\n",
    "\n",
    "explainer = shap.TreeExplainer(booster, feature_perturbation = \"tree_path_dependent\")\n",
    "shap_values = explainer.shap_values(preprocessed_df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の貢献度をプロット\n",
    "shap.summary_plot(shap_values, preprocessed_df_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a895c5",
   "metadata": {},
   "source": [
    "### 予測ごとの判断根拠\n",
    "shap_valuesには各予測に対しての各特徴量の貢献度が格納されています。  \n",
    "これを使うことで、例えばあるレースの結果の予測は、この特徴量が強く影響しているためという表現ができるようになります。  \n",
    "\n",
    "検証用データの0番目の予測結果を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "shap_v = pd.DataFrame(shap_values[1], columns=preprocessed_df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5088e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果に対しでpositiveな影響を与えている特徴量\n",
    "shap_v.iloc[idx].sort_values(ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果に対しでnegativeな影響を与えている特徴量\n",
    "shap_v.iloc[idx].sort_values(ascending=True).iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455da7b5",
   "metadata": {},
   "source": [
    "## 精度検証\n",
    "\n",
    "特徴量の貢献度はあらかた調べられたので、締め括りとしてこのモデルの精度の評価をしましょう。\n",
    "今回の精度指標は、  \n",
    "`レース内で最も1着である確率である確率が高いと評価された選手が実際に1着であった確率`  \n",
    "と設定します。\n",
    "\n",
    "データは１行で1選手を表現しているため、1レース単位は複数行を集約する必要があります。  \n",
    "groupbyを使ってレースごとのindexを取得していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_groups = df_test.groupby(['RaceId']).groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87325e20",
   "metadata": {},
   "source": [
    "### 着順の多クラス分類モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f283cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果の取得\n",
    "prediction_result = booster.predict(preprocessed_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果の0番目の出力\n",
    "# 9つの要素がありそれぞれが各ラベルの確率を表現しています、つまり合計は1になります\n",
    "\n",
    "# Challengeで目的変数を2値分類にした場合出力される予測結果の形変わります\n",
    "print(prediction_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# レースごとの出力値の0番目(1着と推定した確率)がもっとも大きい(np.argmax)選手の実際の着順が1着だった数/レースの数\n",
    "[\n",
    "    df_test.iloc[idx[np.argmax(\n",
    "        [\n",
    "            res[0] for res in prediction_result[idx]\n",
    "        ]\n",
    "    )]]['KakuteiJyuni']\n",
    "    for race, idx in race_groups.items()\n",
    "].count(1) / len(race_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b7299-aca1-4dec-ab8c-e32a9e0ea571",
   "metadata": {},
   "source": [
    "========================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803da971",
   "metadata": {},
   "source": [
    "# やってみよう: リアルタイムの競輪レース予測\n",
    "\n",
    "ここまでで、GBDTのハンズオンは一通り終了です。  \n",
    "ですが、折角競輪の予測を作ったので、実際に今日のレースを予測してみましょう！\n",
    "\n",
    "GCSに本日のレースデータのcsvを作成してあります。  \n",
    "このデータに対する予測結果を作成して、今日の全レースに対する予測を作成していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本日のレースデータをGCSから取得\n",
    "prediction_data_path = 'prediction_data/race_data.csv'\n",
    "blob = bucket.blob(prediction_data_path)\n",
    "content = blob.download_as_string()\n",
    "prediction_df = pd.read_csv(BytesIO(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3324666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupsの作成\n",
    "prediction_race_groups = prediction_df.groupby(['JyoCD', 'RaceNum']).groups\n",
    "\n",
    "# 前処理の実行\n",
    "preprocessed_prediction_df = prediction_preprocessing(prediction_df, categorical_encorder)\n",
    "\n",
    "# 予測結果の作成\n",
    "today_prediction_result = booster.predict(preprocessed_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42492b-6db3-47ce-a982-90bd666a63c8",
   "metadata": {},
   "source": [
    "できたら、今日のレースが予想とマッチするかみていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f796a7",
   "metadata": {},
   "source": [
    "### 予測結果の確認\n",
    "まず、今日の全レースの予想を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "velodrome_code = {\n",
    "    11: '函館競輪場', \n",
    "    12: '青森競輪場', \n",
    "    13: 'いわき平競輪場', \n",
    "    21: '弥彦競輪場', \n",
    "    22: '前橋競輪場', \n",
    "    23: '取手競輪場', \n",
    "    24: '宇都宮競輪場', \n",
    "    25: '大宮競輪場', \n",
    "    26: '西武園競輪場', \n",
    "    27: '京王閣競輪場', \n",
    "    28: '立川競輪場', \n",
    "    31: '松戸競輪場', \n",
    "    32: '千葉競輪場', \n",
    "    33: '花月園競輪場', \n",
    "    34: '川崎競輪場', \n",
    "    35: '平塚競輪場', \n",
    "    36: '小田原競輪場', \n",
    "    37: '伊東競輪場', \n",
    "    38: '静岡競輪場', \n",
    "    41: '一宮競輪場', \n",
    "    42: '名古屋競輪場', \n",
    "    43: '岐阜競輪場', \n",
    "    44: '大垣競輪場', \n",
    "    45: '豊橋競輪場', \n",
    "    46: '富山競輪場', \n",
    "    47: '松阪競輪場', \n",
    "    48: '四日市競輪場', \n",
    "    51: '福井競輪場', \n",
    "    52: '大津競輪場', \n",
    "    53: '奈良競輪場', \n",
    "    54: '向日町競輪場', \n",
    "    55: '和歌山競輪場', \n",
    "    56: '岸和田競輪場', \n",
    "    61: '玉野競輪場', \n",
    "    62: '広島競輪場', \n",
    "    63: '防府競輪場', \n",
    "    71: '高松競輪場', \n",
    "    72: '観音寺競輪場', \n",
    "    73: '小松島競輪場', \n",
    "    74: '高知競輪場', \n",
    "    75: '松山競輪場', \n",
    "    81: '小倉競輪場', \n",
    "    83: '久留米競輪場', \n",
    "    84: '武雄競輪場', \n",
    "    85: '佐世保競輪場', \n",
    "    86: '別府競輪場',\n",
    "    87: '熊本競輪場', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac717022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# コールバック関数を定義する\n",
    "def on_button_clicked(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        race_df = prediction_df[(prediction_df['JyoCD'] == dropdown1.value)&(prediction_df['RaceNum'] == dropdown2.value)]\n",
    "        prediction_result = today_prediction_result[race_df.index]\n",
    "        normed_result = prediction_result / sum(prediction_result)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            '車番': race_df['Syaban'].values,\n",
    "            '予測勝率': [str(round(prob[0] * 100, 1))+'%' for prob in normed_result]\n",
    "        })\n",
    "        # DataGridを作成する\n",
    "        grid = widgets.GridBox(\n",
    "            [widgets.HTML(value=df.to_html(index=False, border=1).replace('<table', '<table cellspacing=0'))],\n",
    "            layout=widgets.Layout(grid_template_columns=\"repeat(3, 100px)\")\n",
    "        )\n",
    "\n",
    "        # DataGridを表示する\n",
    "        display(grid)\n",
    "\n",
    "        \n",
    "# ドロップダウンウィジェットを作成する\n",
    "jyo_list = [(velodrome_code[v], v) for v in prediction_df['JyoCD'].unique()]\n",
    "race_num_list = prediction_df['RaceNum'].unique()\n",
    "dropdown1 = widgets.Dropdown(options=jyo_list, description='場: ')\n",
    "dropdown2 = widgets.Dropdown(options=race_num_list, description='レーズ番号')\n",
    "\n",
    "# ボタンウィジェットを作成する\n",
    "button = widgets.Button(description='Submit')\n",
    "output = widgets.Output()\n",
    "\n",
    "# ボタンクリック時にコールバック関数を呼び出す\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# ウィジェットを表示する\n",
    "display(dropdown1, dropdown2, button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e8704-e4a2-4b87-a729-4c7be7a560b1",
   "metadata": {},
   "source": [
    "予測結果を出力できたら、その予測が当たってるかどうかをTipstarで確認してみましょう。  \n",
    "https://tipstar.com/keirin/channels  \n",
    "過去のレースは既に結果が出ているので、答え合わせができるかと思います。\n",
    "\n",
    "また競輪は比較的高頻度で開催されているので、今の時間帯でもレース開始時間の近いものがあると思います。  \n",
    "上記のURLから、直近のレースを選択してください。\n",
    "そして、そのレースの予測を今一度確認してみてください。    \n",
    "確認できたら、予測とレース結果が同じになることをリアルタイムで確認していきます。  \n",
    "Tipstarにレースの映像があるので、それを見ながら予想した選手を応援しましょう！"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
