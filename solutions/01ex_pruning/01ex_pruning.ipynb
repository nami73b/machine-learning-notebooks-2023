{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "capital-finnish",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-electricity",
   "metadata": {},
   "source": [
    "このハンズオンでは、modelのpruningを行い、得られる効果を確認していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unusual-desire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inclusive-latvia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 10:07:28.044446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 10:07:30.652872: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-10 10:07:30.653003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-10 10:07:30.653015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-cookbook",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "評価で使用するため、再度Fashion-MNISTデータセットをロードして、\n",
    "前処理も行なっておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dressed-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28, 1)\n",
      "X_test shape (10000, 28, 28, 1)\n",
      "one hot label shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = fashion_mnist.load_data()\n",
    "\n",
    "## shapeを(batch_size, rows, cols, channels)にexpandする\n",
    "X_train = np.expand_dims(X_train_orig, -1)\n",
    "X_test = np.expand_dims(X_test_orig, -1)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "\n",
    "## グレースケールの 0-255 の値を 正規化して 0-1 の浮動小数にする\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "## one hot vectorにする\n",
    "y_train = tf.keras.utils.to_categorical(y_train_orig, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test_orig, 10)\n",
    "\n",
    "print(\"one hot label shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-variation",
   "metadata": {
    "tags": []
   },
   "source": [
    "### モデルのロード\n",
    "01で保存したFashion-MNISTモデルをロードします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deeced01-dd04-4e31-b24a-0b04e0a481fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 10 10:07:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P0    26W /  70W |      0MiB / 15360MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 01の学習によってgpuのプロセスが残っている場合は、消去する\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7803cce6-636b-4c67-9035-b473fece83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill <<PIDを指定>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "essential-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 10:07:57.468292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:57.480524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:57.482225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:57.484465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 10:07:57.484912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:57.486591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:57.488289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:58.210958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:58.212806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:58.214399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-10 10:07:58.215898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13582 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "## <todo> 自分の名前を入力してください\n",
    "USER    = \"___\" # 自分の名前\n",
    "BUCKET  = \"mixi-ml-handson-2023\"\n",
    "VERSION = \"001\"\n",
    "\n",
    "base_model = tf.keras.models.load_model(\"gs://{}/{}/{}\".format(BUCKET, USER, VERSION))\n",
    "\n",
    "# ベースモデルを一時保存しておく\n",
    "_, base_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(base_model, base_model_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-pastor",
   "metadata": {},
   "source": [
    "### ベースモデルの精度確認\n",
    "再度、ベースモデルの評価を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "matched-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 10:08:04.138631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 3ms/step - loss: 0.2372 - categorical_accuracy: 0.9252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2372296154499054, 0.9251999855041504]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = base_model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(\"loss: {}, Accuracy: {}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-andrew",
   "metadata": {},
   "source": [
    "### 重みの確認\n",
    "\n",
    "pruningとは、重みが小さいエッジを取り去って、パラメータを削減する手法です。  \n",
    "パラメータが少なくなれば、その分モデルのサイズは小さくなり、高速化されます。  \n",
    "しかし、今回のモデルの重みに削減する余地はあるでしょうか。\n",
    "\n",
    "実際に重みの値を確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-license",
   "metadata": {},
   "source": [
    "まず、再度モデルの構成を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "endless-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               819328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,362\n",
      "Trainable params: 876,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-belly",
   "metadata": {},
   "source": [
    "この中のうち、`conv2d`と`dense`が層を構成しています。  \n",
    "これらの層の重みからヒストグラムを作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "female-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_weights_histgram(model, layers_index, bins=1000):\n",
    "    weight_list = model.layers[layers_index].weights[0].numpy().flatten()\n",
    "    plt.hist(weight_list, bins=bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "christian-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# conv2dまたはdense層のindexを入れて、それぞれの重みをplotしてみましょう\n",
    "draw_weights_histgram(base_model, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-village",
   "metadata": {},
   "source": [
    "だいたいどの層をplotしてみても、0.0付近に値が集中していたのではないでしょうか。  \n",
    "0.0付近のweightは、消去しても精度に大きな影響を与えないはずなので、このモデルにはpruningする余地が十分あるといえそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-intent",
   "metadata": {},
   "source": [
    "### pruningモデルを定義\n",
    "公式の[Pruning in Keras example](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)を参考にpruningモデルを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "similar-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def compute_necessary_steps(batch_size, epochs):\n",
    "    return np.ceil(X_train.shape[0] / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "end_step = compute_necessary_steps(batch_size=16, epochs=5)\n",
    "\n",
    "# 最初に10%をpruning、最終的には70%をpruningする様にスケジューリング\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.10,\n",
    "                                                               final_sparsity=0.70,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(base_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "clear-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-opposition",
   "metadata": {},
   "source": [
    "### 学習\n",
    "pruningモデルが定義できたので、再学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "vital-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 10:19:14.166698: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/prune_low_magnitude_dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/3375 [..............................] - ETA: 3:29:34 - loss: 0.1211 - categorical_accuracy: 1.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0059s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "3375/3375 [==============================] - 27s 7ms/step - loss: 0.1583 - categorical_accuracy: 0.9414 - val_loss: 0.2221 - val_categorical_accuracy: 0.9292\n",
      "Epoch 2/5\n",
      "3375/3375 [==============================] - 23s 7ms/step - loss: 0.1261 - categorical_accuracy: 0.9529 - val_loss: 0.2281 - val_categorical_accuracy: 0.9332\n",
      "Epoch 3/5\n",
      "3375/3375 [==============================] - 24s 7ms/step - loss: 0.1254 - categorical_accuracy: 0.9531 - val_loss: 0.2360 - val_categorical_accuracy: 0.9312\n",
      "Epoch 4/5\n",
      "3375/3375 [==============================] - 23s 7ms/step - loss: 0.1186 - categorical_accuracy: 0.9548 - val_loss: 0.2460 - val_categorical_accuracy: 0.9327\n",
      "Epoch 5/5\n",
      "3375/3375 [==============================] - 23s 7ms/step - loss: 0.1126 - categorical_accuracy: 0.9564 - val_loss: 0.2370 - val_categorical_accuracy: 0.9335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea701caf50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%rm -rf ./pruning_logs\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='pruning_logs'),\n",
    "]\n",
    "model_for_pruning.fit(X_train, y_train, batch_size=16, epochs=5, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-swiss",
   "metadata": {},
   "source": [
    "### 評価\n",
    "学習が終わったら、これまでと同じように評価してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "killing-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2664 - categorical_accuracy: 0.9288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2663879990577698, 0.9287999868392944]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model_for_pruning.evaluate(X_test, y_test, batch_size=16)\n",
    "print(\"loss: {}, Accuracy: {}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-oasis",
   "metadata": {},
   "source": [
    "モデルの精度はベースモデルと比較してどうなっているでしょうか。  \n",
    "ほとんど変わってなければ、精度に影響を与えずにpruningされていることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-signal",
   "metadata": {},
   "source": [
    "### 可視化\n",
    "01と同じように、学習結果をtensorboardで可視化してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opposite-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "russian-programming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5765dfc73663561\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5765dfc73663561\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir pruning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-mountain",
   "metadata": {},
   "source": [
    "学習の推移やshcedule通りにpruningされていったかなどを確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-patch",
   "metadata": {},
   "source": [
    "### pruningモデルを圧縮\n",
    "pruningすることが出来たので、モデルの圧縮を行いましょう。\n",
    "\n",
    "[公式](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras#create_3x_smaller_models_from_pruning)によると、圧縮を確認するには`tfmot.sparsity.keras.strip_pruning`と標準の圧縮アルゴリズムの適用（gzipなど）の両方が必要とのことなので、\n",
    "その対応をしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "random-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# pruningしたモデルを一時保存\n",
    "_, pruned_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_model_file, include_optimizer=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "editorial-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gzipを適応した後のsizeをkbで返す関数\n",
    "def get_gzipped_model_size_kb(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return int(os.path.getsize(zipped_file) / 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-advisory",
   "metadata": {},
   "source": [
    "準備ができたので、各モデルにおける圧縮の効果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adult-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model size    : 3202 kb\n",
      "pruned model size : 1349 kb\n"
     ]
    }
   ],
   "source": [
    "print(\"base model size    : {} kb\".format(get_gzipped_model_size_kb(base_model_file)))\n",
    "print(\"pruned model size : {} kb\".format(get_gzipped_model_size_kb(pruned_model_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-gender",
   "metadata": {},
   "source": [
    "モデルが1/3ほどに圧縮されたことが確認できているでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m106"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
