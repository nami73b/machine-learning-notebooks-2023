{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "capital-finnish",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-electricity",
   "metadata": {},
   "source": [
    "このチャプターでは、modelのpruningを行っていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unusual-desire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inclusive-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-cookbook",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "評価で使用するため、再度Fashion-MNISTデータセットをロードして、\n",
    "前処理も行なっておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dressed-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28, 1)\n",
      "X_test shape (10000, 28, 28, 1)\n",
      "one hot label shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = fashion_mnist.load_data()\n",
    "\n",
    "## shapeを(batch_size, rows, cols, channels)にexpandする\n",
    "X_train = np.expand_dims(X_train_orig, -1)\n",
    "X_test = np.expand_dims(X_test_orig, -1)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "\n",
    "## グレースケールの 0-255 の値を 正規化して 0-1 の浮動小数にする\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "## one hot vectorにする\n",
    "y_train = tf.keras.utils.to_categorical(y_train_orig, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test_orig, 10)\n",
    "\n",
    "print(\"one hot label shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-variation",
   "metadata": {},
   "source": [
    "### モデルのロード\n",
    "01で保存したFashion-MNISTモデルをロードします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "essential-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 16:49:55.499177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:55.510001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:55.510615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:55.512135: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 16:49:55.512691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:55.513405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:55.513980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:56.009815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:56.010698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:56.011414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 16:49:56.011992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13823 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "USER    = \"rio\" # 自分の名前\n",
    "BUCKET  = \"mixi-ml-handson-2022\"\n",
    "VERSION = \"001\"\n",
    "\n",
    "base_model = tf.keras.models.load_model(\"gs://{}/{}/{}\".format(BUCKET, USER, VERSION))\n",
    "\n",
    "# ベースモデルを一時保存しておく\n",
    "_, base_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(base_model, base_model_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-pastor",
   "metadata": {},
   "source": [
    "### ベースモデルの精度確認\n",
    "再度、ベースモデルの評価を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "matched-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 16:50:08.416941: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 3ms/step - loss: 0.2317 - categorical_accuracy: 0.9279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23173607885837555, 0.9279000163078308]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-andrew",
   "metadata": {},
   "source": [
    "### 重みの確認\n",
    "\n",
    "pruningとは、重みが小さいエッジを取り去って、パラメータを削減する手法になります。  \n",
    "パラメータが少なくなれば、その分モデルのサイズは小さくなり、高速化されます。  \n",
    "しかし、今回のモデルの重みに削減する余地はあるでしょうか。\n",
    "\n",
    "実際に重みの値を確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-license",
   "metadata": {},
   "source": [
    "まず、再度モデルの構成を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "endless-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               819328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,362\n",
      "Trainable params: 876,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-belly",
   "metadata": {},
   "source": [
    "この中のうち、`conv2d`と`dense`が層を構成しています。  \n",
    "これらの層の重みからヒストグラムを作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "female-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_weights_histgram(model, layers_index, bins=1000):\n",
    "    weight_list = model.layers[layers_index].weights[0].numpy().flatten()\n",
    "    plt.hist(weight_list, bins=bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUWklEQVR4nO3df6zd9X3f8eerdkJYWgsYNvNsmInkZoNoJOGOuctWpaMZLlQ1lYpk9QfWxGSVsSjVpnVm1f7YH5Ho/qgSpMGESItR0yKLpsUKJSt1mvWPOpDrhoYYh+IEBle42MmaleYPMuh7f5wP6cn1ub7n2vd+zzn3+3xIR9/veZ/P99z3Off4db73c77n61QVkqR++IFJNyBJ6o6hL0k9YuhLUo8Y+pLUI4a+JPXIxkk3sJzLL7+8duzYMek2JGmmHDt27JtVtXlxfepDf8eOHczPz0+6DUmaKUn+96i60zuS1COGviT1iKEvST1i6EtSj4wV+kkuSfJokq8lOZHkR5JcluTJJC+05aVD4+9OcjLJ80luGqpfn+TZdtu9SbIWD0qSNNq4e/qfBD5XVf8QuA44ARwAjlTVTuBIu06Sa4C9wLXAbuC+JBva/dwP7Ad2tsvuVXockqQxLBv6STYBPwp8CqCqvltV3wb2AAfbsIPArW19D/BIVb1RVS8CJ4EbkmwFNlXV0Rqc2vPhoW0kSR0YZ0//PcAZ4DeSfDnJg0neDVxRVacA2nJLG78NeGVo+4VW29bWF9clSR0ZJ/Q3Ah8E7q+qDwDfoU3lLGHUPH2do372HST7k8wnmT9z5swYLUqSxjFO6C8AC1X1VLv+KIM3gdfalA1teXpo/JVD228HXm317SPqZ6mqB6pqrqrmNm8+61vEUqd2HHj8+5bSLFs29KvqL4BXkry3lW4EngMOA/tabR/wWFs/DOxNclGSqxl8YPt0mwJ6PcmudtTO7UPbSJI6MO65dz4KfDrJO4FvAP+awRvGoSR3AC8DtwFU1fEkhxi8MbwJ3FVVb7X7uRN4CLgYeKJdpKnnXr7Wi0z7/5E7NzdXnnBNkzQq8F+655YJdCKNL8mxqppbXPcbuZLUI4a+JPWIoS9JPWLoS+fgB7habwx9SeoRQ186T/4VoFlk6EvnwcDXrDL0pQtg+GvWGPqS1COGviT1iKEvLcGpG61Hhr4k9YihL10g/yLQLDH0JalHDH1J6hFDX5J6xNCXpB4x9CWpRwx9aRV4BI9mhaEvST1i6EtSjxj6ktQjhr4k9YihL0k9YuhLUo8Y+pLUI2OFfpKXkjyb5Jkk8612WZInk7zQlpcOjb87yckkzye5aah+fbufk0nuTZLVf0iSpKWsZE//x6rq/VU1164fAI5U1U7gSLtOkmuAvcC1wG7gviQb2jb3A/uBne2y+8IfgiRpXBcyvbMHONjWDwK3DtUfqao3qupF4CRwQ5KtwKaqOlpVBTw8tI0kqQPjhn4Bf5DkWJL9rXZFVZ0CaMstrb4NeGVo24VW29bWF9fPkmR/kvkk82fOnBmzRUnScjaOOe5DVfVqki3Ak0m+do6xo+bp6xz1s4tVDwAPAMzNzY0cI0laubH29Kvq1bY8DfwucAPwWpuyoS1Pt+ELwJVDm28HXm317SPqkqSOLBv6Sd6d5IfeXgf+FfBV4DCwrw3bBzzW1g8De5NclORqBh/YPt2mgF5PsqsdtXP70DaSpA6MM71zBfC77ejKjcBvVdXnknwJOJTkDuBl4DaAqjqe5BDwHPAmcFdVvdXu607gIeBi4Il2kSR1ZNnQr6pvANeNqH8LuHGJbT4OfHxEfR5438rblLrl+fG1XvmNXEnqEUNfknrE0JekHjH0JalHDH1J6hFDX5J6xNCXpB4x9CWpRwx9SeoRQ1+SesTQl1aJp27QLDD0JalHDH1J6hFDX5J6xNCXFnFuXuuZoS9JPWLoS1KPGPqS1COGviT1iKEvST1i6EtSjxj6ktQjhr4k9YihL60iv9ilaWfoS1KPGPqS1CNjh36SDUm+nOSz7fplSZ5M8kJbXjo09u4kJ5M8n+Smofr1SZ5tt92bJKv7cCRJ57KSPf2PASeGrh8AjlTVTuBIu06Sa4C9wLXAbuC+JBvaNvcD+4Gd7bL7grqXJK3IWKGfZDtwC/DgUHkPcLCtHwRuHao/UlVvVNWLwEnghiRbgU1VdbSqCnh4aBtJUgfG3dP/BPDLwN8M1a6oqlMAbbml1bcBrwyNW2i1bW19cf0sSfYnmU8yf+bMmTFblCQtZ9nQT/KTwOmqOjbmfY6ap69z1M8uVj1QVXNVNbd58+Yxf6wkaTkbxxjzIeCnktwMvAvYlOQ3gdeSbK2qU23q5nQbvwBcObT9duDVVt8+oi5J6siye/pVdXdVba+qHQw+oP18Vf08cBjY14btAx5r64eBvUkuSnI1gw9sn25TQK8n2dWO2rl9aBtJUgfG2dNfyj3AoSR3AC8DtwFU1fEkh4DngDeBu6rqrbbNncBDwMXAE+0iSerIikK/qr4AfKGtfwu4cYlxHwc+PqI+D7xvpU1KklaH38iVpB4x9CWpRwx9SeoRQ1+SesTQl6QeMfQlqUcMfUnqEUNfknrE0JekHjH0JalHDH1J6hFDXxqy48Djk25BWlOGviT1iKEvST1i6EtSjxj60irzcwFNM0NfknrE0JekHjH0JalHDH2pcS5efWDoS1KPGPqS1COGviT1iKEvsfrz+X4+oGll6EtSjxj6ktQjy4Z+kncleTrJnyU5nuS/tvplSZ5M8kJbXjq0zd1JTiZ5PslNQ/Xrkzzbbrs3SdbmYUmSRhlnT/8N4F9W1XXA+4HdSXYBB4AjVbUTONKuk+QaYC9wLbAbuC/JhnZf9wP7gZ3tsnv1Hop0fpx/V58sG/o18Nft6jvapYA9wMFWPwjc2tb3AI9U1RtV9SJwErghyVZgU1UdraoCHh7aRpLUgbHm9JNsSPIMcBp4sqqeAq6oqlMAbbmlDd8GvDK0+UKrbWvri+ujft7+JPNJ5s+cObOChyNNjx0HHvevCE2dsUK/qt6qqvcD2xnstb/vHMNHzdPXOeqjft4DVTVXVXObN28ep0VJ0hhWdPROVX0b+AKDufjX2pQNbXm6DVsArhzabDvwaqtvH1GXJsY9cfXNOEfvbE5ySVu/GPhx4GvAYWBfG7YPeKytHwb2JrkoydUMPrB9uk0BvZ5kVztq5/ahbSRJHdg4xpitwMF2BM4PAIeq6rNJjgKHktwBvAzcBlBVx5McAp4D3gTuqqq32n3dCTwEXAw80S6SpI5kcCDN9Jqbm6v5+flJt6F1qMupnZfuuaWznyUBJDlWVXOL634jV5J6xNCXOuAHxpoWhr4k9YihL3XEvX1NA0NfknrE0JekHjH0JalHDH2pQ87ra9LG+UautK4YvOoz9/TVKwa++s7QlzrmG48mydCXpB4x9CWpRwx99cY0TatMUy/qF0NfmhCDX5Ng6GvdM1ylv2XoS1KPGPrqBff2pQFDX5og34zUNUNf69oshOos9Kj1w9CXpB4x9CWpRwx9rVtOm0hnM/QlqUcMfa1Ls7aXP2v9anYtG/pJrkzyR0lOJDme5GOtflmSJ5O80JaXDm1zd5KTSZ5PctNQ/fokz7bb7k2StXlYkqRRxtnTfxP4D1X1j4BdwF1JrgEOAEeqaidwpF2n3bYXuBbYDdyXZEO7r/uB/cDOdtm9io9Fmmnu7asLy4Z+VZ2qqj9t668DJ4BtwB7gYBt2ELi1re8BHqmqN6rqReAkcEOSrcCmqjpaVQU8PLSNtGoMT2lpK5rTT7ID+ADwFHBFVZ2CwRsDsKUN2wa8MrTZQqtta+uL66N+zv4k80nmz5w5s5IWJUnnMHboJ/lB4HeAX6qqvzrX0BG1Okf97GLVA1U1V1VzmzdvHrdFSdIyxgr9JO9gEPifrqrPtPJrbcqGtjzd6gvAlUObbwdebfXtI+qSmh0HHnd6SmtqnKN3AnwKOFFVvzZ002FgX1vfBzw2VN+b5KIkVzP4wPbpNgX0epJd7T5vH9pGumDrKSzX02PRdNk4xpgPAb8APJvkmVb7z8A9wKEkdwAvA7cBVNXxJIeA5xgc+XNXVb3VtrsTeAi4GHiiXSRJHcngQJrpNTc3V/Pz85NuQ1NuPe4Zv3TPLZNuQTMsybGqmltc9xu50pRaj29kmjxDX5J6xNCXpph7+1pthr4k9YihL0k9Yuhr5q33KZD1/vjULUNfM81AlFbG0NfM6lPg9+mxam0Z+pLUI4a+JPWIoa+Z1Nfpjr4+bq0eQ18zp6/B19fHrdVl6EszxvDXhTD0NVMMPOnCGPqS1COGvmaGe/nShTP0JalHDH1pBvlXj86XoS9JPWLoaya4Z3s2nxOdD0NfmmEGv1bK0JdmnMGvlTD0NfUMNWn1GPqaaga+tLoMfWkd2HHgcd8gNRZDX1PLEFs5nzMtZ9nQT/LrSU4n+epQ7bIkTyZ5oS0vHbrt7iQnkzyf5Kah+vVJnm233Zskq/9wJEnnMs6e/kPA7kW1A8CRqtoJHGnXSXINsBe4tm1zX5INbZv7gf3AznZZfJ/S97jHKq2NZUO/qv4Y+D+LynuAg239IHDrUP2Rqnqjql4ETgI3JNkKbKqqo1VVwMND20iSOrLxPLe7oqpOAVTVqSRbWn0b8MWhcQut9v/a+uL6SEn2M/irgKuuuuo8W9Qscg9fWlur/UHuqHn6Okd9pKp6oKrmqmpu8+bNq9ac1Be+eWop5xv6r7UpG9rydKsvAFcOjdsOvNrq20fUJa0yA1/ncr6hfxjY19b3AY8N1fcmuSjJ1Qw+sH26TQW9nmRXO2rn9qFtJEkdGeeQzd8GjgLvTbKQ5A7gHuAjSV4APtKuU1XHgUPAc8DngLuq6q12V3cCDzL4cPfrwBOr/Fg0w9w7lbqRwcE002tubq7m5+cn3YbWmKG/dl6655ZJt6AJSHKsquYW1/1GribOwJe6Y+hrogz8tedzrGGGviT1iKEv9YBn4dTbDH1NjCHUPZ9zGfqaCMNHmgxDX50z8CfL57/fDH11ysCRJsvQl3rIN9/+MvTVGYNmunhETz8Z+uqE4TK9/N30i6GvNWeoSNPD0JekHjH0tabcy58Nzu/3h6GvNWOISNPnfP9jdGlJhv3sevt35zn41y/39LWqDHxpurmnr1Vj4K8vw79P9/zXD0NfF8ywX3/8na5fTu/oghgO/eDRPeuHoa/zZgj0j7/z2Wfo67z4j7+/3OufbYa+VsR/8Brma2H2pKom3cM5zc3N1fz8/KTb6D3/cWs5HuEzXZIcq6q5xXWP3tGSDHqthF/smg2Gvr6PQa8L5fH9063z0E+yG/gksAF4sKru6boH/S1DXmtp8evLN4HJ6zT0k2wA/jvwEWAB+FKSw1X1XJd99I3Brmmx3GvRN4W11/We/g3Ayar6BkCSR4A9gKG/BANbfXI+r/eX7rnl+z5P2HHgcd88zqHr0N8GvDJ0fQH4p4sHJdkP7G9X/zrJ82vc1+XAN9f4Z6wVe58Me+/eyL7zq2evD9emxCSe838wqth16GdE7axjRqvqAeCBtW9nIMn8qEObZoG9T4a9d29W+4bp6r3rL2ctAFcOXd8OvNpxD5LUW12H/peAnUmuTvJOYC9wuOMeJKm3Op3eqao3k/w74H8yOGTz16vqeJc9LKGzqaQ1YO+TYe/dm9W+YYp6n/rTMEiSVo8nXJOkHjH0JalHehn6SS5L8mSSF9ry0iXGXZLk0SRfS3IiyY903euInsbqvY3dkOTLST7bZY9LGaf3JFcm+aP2fB9P8rFJ9Np62Z3k+SQnkxwYcXuS3Ntu/0qSD06iz1HG6P3nWs9fSfInSa6bRJ+jLNf70Lh/kuStJD/TZX/nMk7vST6c5Jn2+v5fXfdIVfXuAvw34EBbPwD86hLjDgL/pq2/E7hkVnpvt/974LeAz06673F7B7YCH2zrPwT8OXDNBHrdAHwdeE/73f/Z4j6Am4EnGHz/ZBfw1KSf4xX0/s+AS9v6T8xS70PjPg/8PvAzk+57Bc/7JQzOQHBVu76l6z57uafP4NQPB9v6QeDWxQOSbAJ+FPgUQFV9t6q+3VF/57Js7wBJtgO3AA9209ZYlu29qk5V1Z+29deBEwy+yd21750ypKq+C7x9ypBhe4CHa+CLwCVJtnbd6AjL9l5Vf1JVf9mufpHBd2amwTjPO8BHgd8BTnfZ3DLG6f1ngc9U1csAVdV5/30N/Suq6hQMQgbYMmLMe4AzwG+0KZIHk7y7yyaXME7vAJ8Afhn4m476Gse4vQOQZAfwAeCptW/tLKNOGbL4zWecMZOw0r7uYPAXyzRYtvck24CfBv5Hh32NY5zn/YeBS5N8IcmxJLd31l2zbs+nn+QPgb834qZfGfMuNgIfBD5aVU8l+SSDKYn/skotLulCe0/yk8DpqjqW5MOr2No4P/tCn/e37+cHGezJ/VJV/dVq9LZC45wyZKzTikzA2H0l+TEGof/P17Sj8Y3T+yeA/1RVbyWjhk/MOL1vBK4HbgQuBo4m+WJV/flaNzfcwLpUVT++1G1JXkuytapOtT/HR/2JtQAsVNXbe5mPMgj9NbcKvX8I+KkkNwPvAjYl+c2q+vk1avl7VqF3kryDQeB/uqo+s0atLmecU4ZM62lFxuoryT9mMP33E1X1rY56W844vc8Bj7TAvxy4OcmbVfV7nXS4tHFfM9+squ8A30nyx8B1DD676kRfp3cOA/va+j7gscUDquovgFeSvLeVbmQ6TgE9Tu93V9X2qtrB4FQXn+8i8MewbO8Z/Ev+FHCiqn6tw94WG+eUIYeB29tRPLuA//v29NWELdt7kquAzwC/0OVe5hiW7b2qrq6qHe31/Sjwb6cg8GG818xjwL9IsjHJ32FwluETnXY56U+8J3EB/i5wBHihLS9r9b8P/P7QuPcD88BXgN+jHe0wC70Pjf8w03P0zrK9M5hmqPacP9MuN0+o35sZ7IF9HfiVVvtF4Bfbehj8p0BfB54F5ib9HK+g9weBvxx6jucn3fO4vS8a+xBTcvTOuL0D/5HBDuRXGUxfdtqjp2GQpB7p6/SOJPWSoS9JPWLoS1KPGPqS1COGviT1iKEvST1i6EtSj/x/R8p70qgs8IAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# conv2dまたはdense層のindexを入れて、それぞれの重みをplotしてみましょう\n",
    "draw_weights_histgram(base_model, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-village",
   "metadata": {},
   "source": [
    "だいたいどの層をplotしてみても、0.0付近に値が集中していたのではないでしょうか。  \n",
    "0.0付近のweightは、消去しても精度に大きな影響を与えないはずなので、このモデルにはpruningする余地が十分あるといえそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-intent",
   "metadata": {},
   "source": [
    "### pruningモデルを定義\n",
    "公式の[Pruning in Keras example](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)を参考にpruningモデルを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "similar-italy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  aggregation=tf.VariableAggregation.MEAN)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  aggregation=tf.VariableAggregation.MEAN)\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  trainable=False)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def compute_necessary_steps(batch_size, epochs):\n",
    "    return np.ceil(X_train.shape[0] / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "end_step = compute_necessary_steps(batch_size=32, epochs=5)\n",
    "\n",
    "# 最初に10%をpruning、最終的には70%をpruningする様にスケジューリング\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.10,\n",
    "                                                               final_sparsity=0.70,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(base_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clear-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-opposition",
   "metadata": {},
   "source": [
    "### 学習\n",
    "pruningモデルが定義できたので、再学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vital-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   1/1688 [..............................] - ETA: 1:23:37 - loss: 0.2750 - categorical_accuracy: 0.8438WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_train_batch_end` time: 0.0099s). Check your callbacks.\n",
      "1688/1688 [==============================] - 15s 7ms/step - loss: 0.1466 - categorical_accuracy: 0.9461 - val_loss: 0.1975 - val_categorical_accuracy: 0.9317\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1510 - categorical_accuracy: 0.9432 - val_loss: 0.2040 - val_categorical_accuracy: 0.9303\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1548 - categorical_accuracy: 0.9419 - val_loss: 0.2098 - val_categorical_accuracy: 0.9270\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1637 - categorical_accuracy: 0.9406 - val_loss: 0.2229 - val_categorical_accuracy: 0.9270\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.1530 - categorical_accuracy: 0.9429 - val_loss: 0.2066 - val_categorical_accuracy: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65e1fcf610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%rm -rf ./pruning_logs\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='pruning_logs'),\n",
    "]\n",
    "model_for_pruning.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-swiss",
   "metadata": {},
   "source": [
    "### 評価\n",
    "学習が終わったら、これまでと同じように評価してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2277 - categorical_accuracy: 0.9274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.227738618850708, 0.9273999929428101]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-oasis",
   "metadata": {},
   "source": [
    "モデルの精度はベースモデルと比較してどうなっているでしょうか。  \n",
    "ほとんど変わってなければ、精度に影響を与えずにpruningされていることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-signal",
   "metadata": {},
   "source": [
    "### 可視化\n",
    "01と同じように、学習結果をtensorboardで可視化してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opposite-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "russian-programming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b1952fc8e4d66896\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b1952fc8e4d66896\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir pruning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-mountain",
   "metadata": {},
   "source": [
    "学習の推移やshcedule通りにpruningされていったかなどを確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-patch",
   "metadata": {},
   "source": [
    "### pruningモデルを圧縮\n",
    "pruningすることが出来たので、モデルの圧縮を行いましょう。\n",
    "\n",
    "[公式](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras#create_3x_smaller_models_from_pruning)によると、圧縮を確認するには`tfmot.sparsity.keras.strip_pruning`と標準の圧縮アルゴリズムの適用（gzipなど）の両方が必要とのことなので、\n",
    "その対応をしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "random-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# pruningしたモデルを一時保存\n",
    "_, pruned_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_model_file, include_optimizer=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "editorial-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gzipを適応した後のsizeをkbで返す関数\n",
    "def get_gzipped_model_size_kb(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return int(os.path.getsize(zipped_file) / 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-advisory",
   "metadata": {},
   "source": [
    "準備ができたので、各モデルにおける圧縮の効果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adult-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model size    : 3199 kb\n",
      "pruned model size : 1340 kb\n"
     ]
    }
   ],
   "source": [
    "print(\"base model size    : {} kb\".format(get_gzipped_model_size_kb(base_model_file)))\n",
    "print(\"pruned model size : {} kb\".format(get_gzipped_model_size_kb(pruned_model_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-gender",
   "metadata": {},
   "source": [
    "モデルが1/3ほどに圧縮されたことが確認できているでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
